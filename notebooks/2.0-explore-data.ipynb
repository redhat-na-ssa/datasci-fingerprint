{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37b6df36-7b0b-4308-b697-6a8b370e1332",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualize the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6815b202-1d7b-4ccb-9c61-3fe22a6e7ce5",
   "metadata": {},
   "source": [
    "Before we can start any training, you need to get a feel for the data you have and ask some question."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ccbd724-a054-478a-beb8-e49a292e09ba",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f3751b-f685-4769-9617-1b326112f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import imutils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# scratch directory is apart of the .gitignore to ensure it is not committed to git\n",
    "%env SCRATCH=../scratch\n",
    "! [ -e \"${SCRATCH}\" ] || mkdir -p \"${SCRATCH}\"\n",
    "\n",
    "scratch_path = os.environ.get('SCRATCH', 'scratch')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b723d8bf-fdc5-4db7-85fa-1dac1690f737",
   "metadata": {},
   "source": [
    "# View the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a8cb708-fa20-4a89-a63a-c8e60b28d435",
   "metadata": {},
   "source": [
    "## Lets make sure we have an even (unbiased) number of examples for each type\n",
    "\n",
    "Or we might teach our model that right fingerprints are more common than left ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d2e6c3-d74f-4399-8e3b-dfd637438e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [scratch_path + \"/train/left/\", scratch_path + \"/train/right/\"]\n",
    "\n",
    "file_data = {}\n",
    "\n",
    "for directory in directories:\n",
    "    file_count = sum(len(files) for _, _, files in os.walk(directory))\n",
    "    dir_name = os.path.basename(directory.rstrip('/'))\n",
    "    file_data[dir_name] = file_count\n",
    "\n",
    "# Extract filenames and file counts from the file_data dictionary\n",
    "filenames = list(file_data.keys())\n",
    "file_counts = list(file_data.values())\n",
    "\n",
    "# Create the histogram\n",
    "plt.bar(filenames, file_counts)\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Directory')\n",
    "plt.ylabel('File Count')\n",
    "plt.title('Number of Examples to train')\n",
    "\n",
    "# Rotate the x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3ad8aa-c632-45ae-bddf-373e8c46dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_imshow(title, image):\n",
    "\t# convert the image frame BGR to RGB color space and display it\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\tplt.imshow(image)\n",
    "\tplt.title(title)\n",
    "\tplt.grid(False)\n",
    "\tplt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa47d5aa-cbe8-4f80-a22c-2fabb0e196bc",
   "metadata": {},
   "source": [
    "## Implement OpenCV image loading script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4fdc6-deac-453c-808b-527d4e62e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image and display it to our screen\n",
    "args = {\n",
    "\t\"image\": scratch_path + \"/train/left/1__M_Left_index_finger_CR.png\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b199586b-8798-409d-b7e6-877da4e92c95",
   "metadata": {},
   "source": [
    "## Load the image from disk and grab spatial dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc6d6a-d1d6-44ac-a5a1-2596fd22b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the image set above from disk into image\n",
    "image = cv2.imread(args[\"image\"])\n",
    "(h, w, c) = image.shape[:3]\n",
    "\n",
    "# display the image dimensions\n",
    "print(\"width: {} pixels\".format(image.shape[1]))\n",
    "print(\"heigth: {} pixels\".format(image.shape[0]))\n",
    "print(\"channels: {}\".format(image.shape[2]))\n",
    "\n",
    "# show the image \n",
    "plt_imshow(\"Original\", image)\n",
    "\n",
    "# save the image back to disk and wait for keypress\n",
    "#cv2.imwrite(scratch_path + \"/train_lr/left/1__M_Left_index_finger_CR.png\", image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00ad4779-fd7e-4c49-93d3-05257f30573d",
   "metadata": {},
   "source": [
    "## What does this image look like\n",
    "\n",
    "We use Pillow to open an image (with PIL.Image.open), and immediately convert the PIL.Image.Image object into an 8-bit (dtype=uint8) numpy array. Each inner list represents a pixel.Since it's a black and white image, R, G, and B are all similar. Matplotlib supports float32 and uint8 data types. For grayscale, Matplotlib supports only float32. If your array data does not meet one of these descriptions, you need to rescale it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4a9ad-9eef-438c-bce0-8bc20dcd1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(Image.open(scratch_path + \"/train/left/1__M_Left_index_finger_CR.png\"))\n",
    "print(repr(img))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75029a9c-ec03-4d50-a1c6-ae1abc38171c",
   "metadata": {},
   "source": [
    "Sometimes you want to enhance the contrast in your image, or expand the contrast in a particular region while sacrificing the detail in colors that don't vary much, or don't matter. A good tool to find interesting regions is the histogram. To create a histogram of our image data, we use the hist() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a57abe-9a89-4090-ad0f-130fcd16cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(image.ravel(), bins=range(256), fc='k', ec='k')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "543200e0-62fa-4a6d-8f32-79c515a1fabe",
   "metadata": {},
   "source": [
    "## Crop the border"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "272893ed-4171-45cc-8094-aa8b4d0554f3",
   "metadata": {},
   "source": [
    "There is a border around the image that will make our model think every fingerprint has a border around it, since they don't we want to crop this out. Something to be aware of is if the source ever changes and removes the border we will want to drop the cropping we are about to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f46830-1c65-414f-9d14-0103c85bfc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropping an image with OpenCV is accomplished via simple NumPy\n",
    "# array slices in startY:endY, startX:endX order\n",
    "cropped = image[5:99,2:92]\n",
    "\n",
    "# display the image dimensions\n",
    "print(\"width: {} pixels\".format(image.shape[1]))\n",
    "print(\"heigth: {} pixels\".format(image.shape[0]))\n",
    "print(\"channels: {}\".format(image.shape[2]))\n",
    "\n",
    "# show the image \n",
    "plt_imshow(\"crop out fingerprint border\", cropped)\n",
    "\n",
    "# save the image\n",
    "cv2.imwrite(scratch_path + \"/train_lr/left/1__M_Left_index_finger_CR.png\", cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638f7c6-d2bf-4d5a-a590-893a3f62a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cropped.ravel(), bins=range(256), fc='k', ec='k')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "223a5adb-afa9-4f95-ab7d-00398fd9f3e5",
   "metadata": {},
   "source": [
    "## Image Arithmetic \n",
    "\n",
    "Since we do not want our model to always expect that fingerprint images are dark contrast, we should add variability to each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7939ca-45d2-4308-aad9-5a52b5843574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images are NumPy arrays stored as unsigned 8-bit integers (unit8)\n",
    "# with values in the range [0, 255]; when using the add/subtract\n",
    "# functions in OpenCV, these values will be *clipped* to this range,\n",
    "# even if they fall outside the range [0, 255] after applying the\n",
    "# operation\n",
    "added = cv2.add(np.uint8([200]), np.uint8([100]))\n",
    "subtracted = cv2.subtract(np.uint8([50]), np.uint8([100]))\n",
    "print(\"max of 255: {}\".format(added))\n",
    "print(\"min of 0: {}\".format(subtracted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7bbca5-b9d2-46f8-939a-47fd7473359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using NumPy arithmetic operations (rather than OpenCV operations)\n",
    "# will result in a modulo (\"wrap around\") instead of being clipped\n",
    "# to the range [0, 255]\n",
    "added = np.uint8([200]) + np.uint8([100])\n",
    "subtracted = np.uint8([50]) - np.uint8([100])\n",
    "print(\"wrap around: {}\".format(added))\n",
    "print(\"wrap around: {}\".format(subtracted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c6021-71a0-4830-a803-f91dd4862de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasing the pixel intensities in our input image by 100 is\n",
    "# accomplished by constructing a NumPy array that has the *same\n",
    "# dimensions* as our input image, filling it with ones, multiplying\n",
    "# it by 100, and then adding the input image and matrix together\n",
    "M = np.ones(cropped.shape, dtype=\"uint8\") * 100\n",
    "added = cv2.add(cropped, M)\n",
    "plt_imshow(\"Lighter\", added)\n",
    "\n",
    "# save the image\n",
    "cv2.imwrite(scratch_path + \"/train_lr/left/1__M_Left_index_finger_CR_lighter.png\", added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9dc45f-0c5f-4c00-a4c6-6efc1c29a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(added.ravel(), bins=range(256), fc='k', ec='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77911316-21d9-4ec8-8ae3-1abd5d1eac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly, we can subtract 50 from all pixels in our image and make it\n",
    "# darker\n",
    "M = np.ones(cropped.shape, dtype=\"uint8\") * 50\n",
    "subtracted = cv2.subtract(cropped, M)\n",
    "plt_imshow(\"Darker\", subtracted)\n",
    "\n",
    "# save the image\n",
    "cv2.imwrite(scratch_path + \"/train_lr/left/1__M_Left_index_finger_CR_darker.png\", subtracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1eb56b-3f65-47ef-9785-7333db971c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(subtracted.ravel(), bins=range(256), fc='k', ec='k')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d4f8b66-71d4-4f29-8fc8-8f973fc9adf3",
   "metadata": {},
   "source": [
    "## Rotate the image\n",
    "\n",
    "Because we should expect our model to only identify a fingerprint when it is upright, we should add some rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71c360-0045-43dd-bc4f-af313ea6aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate our image by 33 degrees counterclockwise, ensuring the\n",
    "# entire rotated image still views in the viewing area\n",
    "rotated = imutils.rotate_bound(image, -10)\n",
    "plt_imshow(\"Rotated Without Cropping\", rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549ad081-588d-4ccd-899d-8d04a03c87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = imutils.rotate_bound(image, -20)\n",
    "plt_imshow(\"Rotated Without Cropping\", rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6aee10-7935-4f08-8efc-93c9476b88bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = imutils.rotate_bound(image, -30)\n",
    "plt_imshow(\"Rotated Without Cropping\", rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7448cbd1-d77b-4d66-9862-8db29e4f4aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = imutils.rotate_bound(image, -40)\n",
    "plt_imshow(\"Rotated Without Cropping\", rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095588b-6181-4d0b-94a8-7ab886447ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = imutils.rotate_bound(image, -50)\n",
    "plt_imshow(\"Rotated Without Cropping\", rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd28f3-d105-4ea9-93d2-94e0b885bc48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
