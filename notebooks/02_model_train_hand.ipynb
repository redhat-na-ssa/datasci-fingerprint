{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e694129-ca72-4c0b-97a7-35f1dc94bac5",
   "metadata": {},
   "source": [
    "# Part III: Model Training for Left Right Fingerprints\n",
    "\n",
    "Now that we understand our data and have it normalized, we can begin experimenting with a model that will predict if a fingerprint originated from a left or right hand. Is this simple, yes. This will allow us to get into production faster and improve the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4151a4-30f5-4492-b5b2-6c43239b5019",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import TensorFlow and other necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827d3ea-44e2-4140-b4fc-f772cf7aaf9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b58ee8-b7fe-440e-b030-4c3b0c263992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ea413-ead1-4553-a335-3345fab2d18e",
   "metadata": {},
   "source": [
    "## Check TF and Cuda versions\n",
    "\n",
    "For reference [see this chart](https://www.tensorflow.org/install/source#gpu)\n",
    "\n",
    "Expected output\n",
    "```\n",
    "TensorFlow: 2.14.0\n",
    "TensorFlow Datasets: 4.9.3\n",
    "OpenCV version: 4.8.1\n",
    "Cuda version: 11.8\n",
    "cudnn version: 8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a1827-1028-4572-822c-f72ef317dcab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check versions for Tensorflow and Cuda\n",
    "print('TensorFlow: ' + tf.__version__)\n",
    "print('TensorFlow Datasets: ' + tfds.__version__)\n",
    "print('OpenCV version: ' + cv2.__version__)\n",
    "\n",
    "# Check CUDA Version\n",
    "sys_details = tf.sysconfig.get_build_info()\n",
    "cuda_version = sys_details[\"cuda_version\"]\n",
    "print('Cuda version: ' + cuda_version)\n",
    "\n",
    "# Check CUDNN Version\n",
    "cudnn_version = sys_details[\"cudnn_version\"]  \n",
    "print('cudnn version: ' + cudnn_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1f3d5-bb9f-4ac7-8c53-100d63135afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scratch directory is apart of the .gitignore to ensure it is not committed to git\n",
    "%env SCRATCH=../scratch\n",
    "! [ -e \"${SCRATCH}\" ] || mkdir -p \"${SCRATCH}\"\n",
    "\n",
    "scratch_path = os.environ.get('SCRATCH', './scratch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78145951-8608-4868-bb48-bfdb0f32127b",
   "metadata": {},
   "source": [
    "# Create the training and validation dataset\n",
    "\n",
    "This function streamlines the creation of TensorFlow datasets for training and validation, encapsulating several steps such as loading, preprocessing, caching, and prefetching, making it easier to manage datasets for machine learning models.\n",
    "\n",
    "### Function's Main Operations:\n",
    "\n",
    "- image_dataset_from_directory: Utilizes TensorFlow's image_dataset_from_directory function to create a dataset from the specified directory with provided configurations.\n",
    "Data Transformations:\n",
    "- cache: Caches the dataset in memory after the initial data loading for faster access during training.\n",
    "- shuffle: Shuffles the dataset with a buffer size of 1000.\n",
    "- prefetch: Prefetches data, preparing subsequent batches while the model is executing computations on the current batch, optimizing data pipeline performance.\n",
    "\n",
    "### Return:\n",
    "\n",
    "Returns the processed dataset ready for training or validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e411ab-72bc-477a-9714-d09cbb32efd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def create_image_dataset(directory, color_mode=\"grayscale\", validation_split=0.2,\n",
    "                         subset=None, seed=123, image_size=(96, 96), batch_size=32):\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory,\n",
    "        color_mode=color_mode,\n",
    "        validation_split=validation_split,\n",
    "        subset=subset,\n",
    "        seed=seed,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082855ad-655d-4c21-b897-77ec25055b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = create_image_dataset(\n",
    "    scratch_path + '/processed/hand',\n",
    "    subset=\"training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1f63c-e70d-4667-89bd-1744f2d1881a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_ds = create_image_dataset(\n",
    "    scratch_path + '/processed/hand',\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72592fdb-0c84-4408-8e00-2317a2cbaf3b",
   "metadata": {},
   "source": [
    "Here are the first nine images from the training dataset with their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3dd923-4737-4436-815b-3acc0291c31c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get class names by iterating through train_ds and adding 'left' and 'right'\n",
    "class_names = train_ds.class_names if hasattr(train_ds, 'class_names') else [str(label) for label in sorted(set(train_ds.map(lambda x, y: y).unbatch().as_numpy_iterator()))]\n",
    "class_names += ['left', 'right']\n",
    "class_names = sorted(set(class_names))  # Ensure uniqueness and sort\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b48d4-812f-4ab6-a517-5dee73afc7ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_mapping = {0: 'left', 1: 'right'}  # Define the mapping\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"), cmap='gray')\n",
    "        # Replace label with corresponding class name using the mapping\n",
    "        plt.title(label_mapping.get(labels[i].numpy(), 'Unknown'))\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78986964-233b-463a-87c6-c5eb0f34013f",
   "metadata": {},
   "source": [
    "Pass the datasets to the Keras Model.fit method for training in later steps.\n",
    "\n",
    "Use the image_batch tensor of  shape (32, 96, 96, 1), which splits batch of 32 images of shape 96x96x3 (the last dimension refers to color channels grayscale). The label_batch is a tensor of the shape (32,), these are corresponding labels to the 32 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca09039-516a-443f-8501-b886ae5ef2ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f463d46e-765d-4b58-847a-4ced5a12fb3a",
   "metadata": {},
   "source": [
    "## Distrubited Training Strategy\n",
    "\n",
    "`tf.distribute.Strategy` is a TensorFlow API to distribute training across multiple GPUs, multiple machines, or TPUs. Using this API, you can distribute your existing models and training code with minimal code changes. [Types of strategies](https://www.tensorflow.org/guide/distributed_training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd3427-9893-42ce-a8fa-411104eacb30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a7f1f-67da-42e5-907a-fc9ff2c61066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7694d91-270b-4100-86d1-b69c96cd1454",
   "metadata": {},
   "source": [
    "## GPU Memory Allocation\n",
    "\n",
    "The `TF_GPU_ALLOCATORvariable` enables the memory allocator using cudaMallocAsync available since CUDA 11.2. It has fewer fragmentation issues than the default BFC memory allocator. Note, this could become the default in the future.\n",
    "\n",
    "This environment variable is unset by default. To enable the variable, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cbdfa4-1e91-43c6-8c0d-0d0d56ab7f87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cuda_malloc_async has fewer fragmentation issues than the default BFC memory allocator - https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tf_gpu_allocator\n",
    "TF_FORCE_GPU_ALLOW_GROWTH=True\n",
    "\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "print(os.getenv(\"TF_GPU_ALLOCATOR\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f3174-3543-4385-8465-634493787e5d",
   "metadata": {},
   "source": [
    "## Create Model Function\n",
    "\n",
    "This function encapsulates the creation and compilation of a CNN model for image classification tasks. It provides flexibility to specify the class names and input image shape, enabling the user to adapt the model for different classification problems and data formats.\n",
    "\n",
    "### Function's Main Operations:\n",
    "- Model Creation:\n",
    "    - Utilizes a distributed strategy (tf.distribute.MirroredStrategy()) for training across multiple devices (if available).\n",
    "    - Constructs a sequential model using Keras (Sequential).\n",
    "    - The model architecture consists of several layers:\n",
    "        - Convolutional layers (Conv2D) with varying filter sizes and activation functions (ReLU), followed by max-pooling layers (MaxPooling2D).\n",
    "        - Flattening layer (Flatten) to transform the output of the convolutional layers into a 1D tensor.\n",
    "        - Dense layers (Dense) for classification, with ReLU activation for hidden layers and linear activation for the output layer.\n",
    "\n",
    "### Compilation:\n",
    "- Compiles the model using the Adam optimizer ('adam'), sparse categorical cross-entropy loss function (tf.keras.losses.SparseCategoricalCrossentropy), and accuracy as the metric for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35837bf8-d347-4bf2-a3f9-6d99c91df8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "def create_model(class_names=None, input_image_shape=(96, 96, 1)):\n",
    "    if class_names is None:\n",
    "        class_names = ['left', 'right',]  # Define default class names here\n",
    "\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = Sequential([\n",
    "          layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=input_image_shape, name=\"model\"),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "          layers.MaxPooling2D(),\n",
    "          layers.Flatten(),\n",
    "          layers.Dense(128, activation='relu'),\n",
    "          layers.Dense(num_classes)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0514e581-ca0a-486c-8d7b-d06a7c831988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build and compile the mode\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397c8f21-9b06-44ff-a508-e314dc337828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c945567-0246-4637-9e44-f69a0ceed274",
   "metadata": {},
   "source": [
    "## Training Function\n",
    "\n",
    "This function streamlines the process of training a neural network model by encapsulating the training routine with a specific model, datasets, and epochs, allowing for easier experimentation and training within the notebook or Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b37f4-9033-4108-88e4-d0a7a926f557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_data=train_ds, val_data=val_ds, epochs=10):\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=val_data,\n",
    "        epochs=epochs\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca122b31-d063-45eb-a597-7650a8c8d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have your 'model', 'train_ds', and 'val_ds' variables defined\n",
    "trained_history = train_model(model, train_ds, val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9f38a-8c94-4814-bf2e-c64f637f9c84",
   "metadata": {},
   "source": [
    "The performance metrics  give insight into how well your model has learned from the training data and how well it generalizes to unseen validation data.\n",
    "\n",
    "- Loss: This represents the error or discrepancy between the predicted and actual values. Lower values indicate better performance, as it implies that the model's predictions are closer to the actual values.\n",
    "- Accuracy: This metric indicates the proportion of correctly classified samples out of the total samples. An accuracy of 0.9443 for training data means that the model correctly predicted the classes for approximately 94.43% of the training set.\n",
    "- Val_loss (Validation Loss): This measures the error between the predicted values and the actual values on the validation dataset. Similar to training loss, lower values are better, indicating that the model generalizes well to unseen data.\n",
    "- Val_accuracy (Validation Accuracy): This represents the proportion of correctly classified samples out of the total samples in the validation dataset. An accuracy of 0.8967 for validation data suggests that the model correctly predicted the classes for approximately 89.67% of the validation set.\n",
    "\n",
    "Overall, a high training accuracy and a relatively close validation accuracy indicate that the model is performing well, but you may want to watch out for overfitting and fine-tune the model further if necessary. Regularization techniques, adjusting model complexity, or increasing data diversity might help improve generalization to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb2e76-f1a1-4e94-9c00-a52aead1cf64",
   "metadata": {},
   "source": [
    "## Performance Visualization Function\n",
    "\n",
    "This function, plot_training_history, takes in the history object returned by the model's fit method and the epochs parameter. It then plots the training and validation accuracy as well as the training and validation loss in two subplots, providing insights into the model's performance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6567c-6634-4893-b065-8b89b126d9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def plot_training_history(history, epochs, save_dir=None):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    # Save the plot to a directory if specified\n",
    "    if save_dir:\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        \n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        plot_filename = f\"training_history_plot_{current_time}.png\"\n",
    "        plot_path = os.path.join(save_dir, plot_filename)\n",
    "        \n",
    "        plt.savefig(plot_path)\n",
    "        print(f\"Plot saved to: {plot_path}\")\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9bb34d-7028-4258-802f-0c059ae93769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute the performance visualization\n",
    "plot_training_history(history=trained_history, epochs=10, save_dir='../reports/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73954898-4248-4570-90bc-0e7f07be459a",
   "metadata": {},
   "source": [
    "# Serialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2f275-7a70-4b6b-b80e-289ec0054f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_version = os.environ.get('VERSION', \"1\")\n",
    "\n",
    "model_path = scratch_path + \"/models/hand/\" + model_version + \"/model.savedmodel\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4236e-73d1-4663-a14d-ecb32ba147b4",
   "metadata": {},
   "source": [
    "# Test with a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55edf860-861b-4b10-9eec-03cd13895f66",
   "metadata": {},
   "source": [
    "## Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70b0f3-a4b2-4892-b19b-9b42a2163486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = scratch_path + \"/models/hand/\" + model_version + \"/model.savedmodel\"\n",
    "model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d96457-83a5-4fee-9338-ac6f7a14b00b",
   "metadata": {},
   "source": [
    "## Load a random sample input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80a47f-8881-4a3b-ac92-b9254d06045b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select random images\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "samples_path = scratch_path + \"/processed/real/\"\n",
    "file_list = os.listdir(samples_path)\n",
    "print('Files in path: ' + str(len(file_list)))\n",
    "\n",
    "test_image = random.choice(file_list)\n",
    "print('Selected: ' + test_image)\n",
    "\n",
    "# loads an image into PIL format.\n",
    "img = tf.keras.utils.load_img(\n",
    "    samples_path + test_image,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(96, 96),\n",
    "    #interpolation='nearest',\n",
    ")\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "\n",
    "# converts a PIL image instance to a numpy array\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "print(\"shape:\",img_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e9f03e-80c2-428e-abac-ff70fefc5e84",
   "metadata": {},
   "source": [
    "## Generate a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e943e2f2-3fd7-4637-b87c-988ee1947b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "class_mapping = {0: 'left', 1: 'right'}  # Define your class mapping\n",
    "\n",
    "predicted_label = class_mapping[np.argmax(score)]\n",
    "confidence = 100 * np.max(score)\n",
    "\n",
    "print(\n",
    "    f\"This image {test_image} is predicted as {predicted_label} with a {confidence:.2f}% confidence.\"\n",
    ")\n",
    "\n",
    "# Check if the predicted label is in the test image name (case insensitive)\n",
    "is_label_in_image_name = predicted_label.lower() in test_image.lower()\n",
    "print(f\"Is predicted label in the image name? {is_label_in_image_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72dd222-1895-4d30-a951-c4063006856c",
   "metadata": {},
   "source": [
    "# Upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c663c98-0097-4530-88e3-e0d9613d3513",
   "metadata": {},
   "source": [
    "## List the available buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f98fbf4-d8d5-4099-b748-c921ab5c5dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list objects using the aws s3 cli\n",
    "! aws s3 ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc4f42-b699-4de3-8f10-8de45d84ebf9",
   "metadata": {},
   "source": [
    "## List the dynamically created bucket for the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc09ec4-37e9-41fd-812f-f6cd840019cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "response = s3_client.list_buckets()\n",
    "\n",
    "filtered_buckets=[]\n",
    "\n",
    "for bucket in response['Buckets']:\n",
    "    bucket_name = bucket['Name']\n",
    "    if bucket_name.startswith('sagemaker-fingerprint-'):\n",
    "        filtered_buckets.append(bucket_name)\n",
    "    \n",
    "print(filtered_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6b31ee-2250-40f2-bcbe-56c32eb46776",
   "metadata": {},
   "source": [
    "## Upload the model to the demo bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29b86e-8527-4b41-b44c-1073dafb75f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for bucket in filtered_buckets:\n",
    "    command = f\"aws s3 sync ../scratch/models/hand s3://{bucket}/models/hand\"\n",
    "    subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9702f9d-03c1-46e7-ae3f-60b9e728cae8",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "Congrats! We have our first baseline model that predicts which hand an unknown fingerprint originated stored in AWS S3. Next:\n",
    "\n",
    "Verify the model in AWS S3:\n",
    "1. Go to your AWS Console\n",
    "1. Go to S3 and navigate to the sagemaker-fingerprint-data- bucket\n",
    "1. Go to the models subdirectory and step into the directories if you want\n",
    "\n",
    "Check inference:\n",
    "1. Go to your OpenShift Console\n",
    "1. Navigate to the *Project* `models`\n",
    "1. Under *Networking* go to *Routes*\n",
    "1. Click the `gradio-client` URL\n",
    "1. Interact with the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf7fd0-8441-4470-8e22-a028b815862b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
