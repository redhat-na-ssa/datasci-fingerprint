{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb86f8e1-b38b-4d0c-92b5-257c657ce304",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0685747-4565-4cf5-ae05-ed5d7ea051da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 09:12:43.226760: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "# Install packages and frameworks\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import visualkeras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "# expecting 2.11\n",
    "# if 2.7, than logging errors will show \"Cleanup called...\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5bee99-149d-4711-aa7b-9d4d473ca677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually set a filename to store and compare reports\n",
    "os.environ['FILENAME'] = 'train_tune'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba71e1f6-f29c-4c35-8a92-a60c8851fd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SCRATCH=../scratch\n"
     ]
    }
   ],
   "source": [
    "# scratch directory is apart of the .gitignore to ensure it is not committed to git\n",
    "%env SCRATCH=../scratch\n",
    "! [ -e \"${SCRATCH}\" ] || mkdir -p \"${SCRATCH}\"\n",
    "\n",
    "scratch_path = os.environ.get('SCRATCH', './scratch')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3edfc60d-2aec-4516-8cb7-8837441b8391",
   "metadata": {},
   "source": [
    "# Load the saved datasets\n",
    "\n",
    "The TFRecord format is a simple format for storing a sequence of binary records."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09b36548-1911-471b-b899-4fef4ce79e41",
   "metadata": {},
   "source": [
    "## Load train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f78a37af-782f-4473-8f69-e73c6cc02a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: AMD Radeon Pro 560\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 2.00 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 09:12:52.737811: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-06-08 09:12:52.739135: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = scratch_path + '/tf_datasets/train/'\n",
    "train_ds = tf.data.Dataset.load(path)\n",
    "train_ds.element_spec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52fa4bb5-7b2e-4b04-801f-c4f9f9d8d565",
   "metadata": {},
   "source": [
    "## Load validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cedab0e-4fca-4006-8c1d-3228baa0cd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = scratch_path + '/tf_datasets/validate/'\n",
    "validation_ds = tf.data.Dataset.load(path)\n",
    "validation_ds.element_spec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c720750-8f09-4d46-ba9a-fa055776b466",
   "metadata": {},
   "source": [
    "## Load test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16460065-67d2-455c-b03f-ef59b553d74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = scratch_path + '/tf_datasets/test/'\n",
    "test_ds = tf.data.Dataset.load(path)\n",
    "test_ds.element_spec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33454bbd-1c97-4e68-b588-f594a65096e7",
   "metadata": {},
   "source": [
    "## Apply augmentation\n",
    "\n",
    "When you don't have a large image dataset or when your images are all set in a single direction like ours are, it's a good practice to artificially introduce sample diversity by applying random, yet realistic, transformations to the training images, such as rotation and horizontal flipping. This helps expose the model to different aspects of the training data and reduce over-fitting. \n",
    "\n",
    "Learn more https://www.tensorflow.org/tutorials/images/data_augmentation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75aed332-c534-434a-b359-1d8b5673aecc",
   "metadata": {},
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "\n",
    "  # randomly rotates images during training\n",
    "  tf.keras.layers.RandomRotation(\n",
    "    # a float represented as fraction of 2 Pi, or a tuple of size 2 representing lower and upper bound for rotating clockwise and counter-clockwise. \n",
    "    # A positive values means rotating counter clock-wise, while a negative value means clock-wise. \n",
    "    0.2,\n",
    "      \n",
    "    # Points outside the boundaries of the input are filled according to the given mode (one of {\"constant\", \"reflect\", \"wrap\", \"nearest\"}).\n",
    "    fill_mode='constant',\n",
    "      \n",
    "    # Supported values: \"nearest\", \"bilinear\".\n",
    "    interpolation='nearest',\n",
    "      \n",
    "    # Integer. Used to create a random seed.\n",
    "    seed=None,\n",
    "      \n",
    "    # the value to be filled outside the boundaries when fill_mode=\"constant\".\n",
    "    fill_value=0.0,\n",
    "),\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95b7454a-3458-4213-9265-dd25d88f1466",
   "metadata": {},
   "source": [
    "## Configure the datasets for performance\n",
    "\n",
    "Let's make sure to use buffered prefetching so we can yield data from disk without having I/O become blocking. These are two important methods you should use when loading data.\n",
    "\n",
    "1. `Caching` a dataset, either in memory or on local storage. This will save some operations (like file opening and data reading) from being executed during each epoch.\n",
    "1. `Prefetching` overlaps the preprocessing and model execution of a training step. While the model is executing training step s, the input pipeline is reading the data for step s+1. Doing so reduces the step time to the maximum (as opposed to the sum) of the training and the time it takes to extract the data.\n",
    "\n",
    "[Optimising your input pipeline performance with tf.data (part 1)](https://towardsdatascience.com/optimising-your-input-pipeline-performance-with-tf-data-part-1-32e52a30cac4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d442d41-0c11-4726-955b-fa72d3e5ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8da87c9-0c6b-49af-ae0e-c0f3b98515a0",
   "metadata": {},
   "source": [
    "# Check the device spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c2bee89-fe70-4b71-ac4e-c95c47bd7661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display physical devices\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8cd9a82-7cad-401d-8928-0cb0c4b3e7bf",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "138ee5cd-c5af-41d8-a208-643ea43d0eb9",
   "metadata": {},
   "source": [
    "## Set some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df80906c-92fe-4ea5-a79b-d16ceee15728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for consistency\n",
    "img_height = 96              # desired height\n",
    "img_width = 96               # desired width\n",
    "batch_size = 32              # batch inputs in 32\n",
    "seed_train_validation = 42   # Must be same for train_ds and val_ds\n",
    "validation_split = 0.3       # move 30% of the data into validation\n",
    "class_names = ['left', 'right']\n",
    "\n",
    "dataFormat=\"channels_last\"\n",
    "num_classes = len(class_names)\n",
    "inputShape=(img_height, img_width, 1)\n",
    "chanDim = -1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "232d3709-db26-4a83-ac98-a36013a86e76",
   "metadata": {},
   "source": [
    "## Define a model and hyperparameters\n",
    "\n",
    "When you build a model for hypertuning, you also define the hyperparameter search space in addition to the model architecture. The model you set up for hypertuning is called a hypermodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6266324-4d51-478f-8a16-ce4359e78f3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_tuner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras_tuner\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mkt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m num_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(class_names)\n\u001b[1;32m     10\u001b[0m inputShape\u001b[39m=\u001b[39m(img_height, img_width, \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_tuner'"
     ]
    }
   ],
   "source": [
    "# build model from scratch\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout,Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "inputShape=(img_height, img_width, 1)\n",
    "data_format=\"channels_last\"\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential(name=\"fingerprint_prediction\")\n",
    "    # comment out to remove augmentation\n",
    "    #data_augmentation\n",
    "    input_shape=(img_height, img_width, 1)\n",
    "    chanDim = -1\n",
    "    # first CONV => RELU => POOL layer set\n",
    "    model.add(Conv2D(\n",
    "        hp.Int(\"conv_1\", min_value=32, max_value=96, step=32),\n",
    "        (3, 3), padding=\"same\", input_shape=inputShape, data_format=data_format))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # second CONV => RELU => POOL layer set\n",
    "    model.add(Conv2D(\n",
    "        hp.Int(\"conv_2\", min_value=64, max_value=128, step=32),\n",
    "        (3, 3), padding=\"same\", data_format=data_format))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # third CONV => RELU => POOL layer set\n",
    "    model.add(Conv2D(\n",
    "        hp.Int(\"conv_3\", min_value=96, max_value=256, step=32),\n",
    "        (3, 3), padding=\"same\", data_format=data_format))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    \n",
    "    # first (and only) set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hp.Int(\"dense_units\", min_value=256,\n",
    "                           max_value=768, step=256)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    # softmax classifier\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    # initialize the learning rate choices and optimizer\n",
    "    lr = hp.Choice(\"learning_rate\",\n",
    "                   values=[1e-1, 1e-2, 1e-3])\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    # return the model\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=tf.losses.CategoricalCrossentropy(from_logits=False),\n",
    "        # metrics to be evaluated by the model during training and testing.The strings 'accuracy' or 'acc', TF converts this to binary, categorical or sparse.\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed10cdd7-2610-4182-8237-caba3e5ad785",
   "metadata": {},
   "source": [
    "## Define a training strategy \n",
    "\n",
    "tf.distribute.Strategy is a TensorFlow API to distribute training across multiple GPUs, multiple machines, or TPUs. Using this API, you can distribute your existing models and training code with minimal code changes.\n",
    "- Easy to use and support multiple user segments, including researchers, machine learning engineers, etc.\n",
    "- Provide good performance out of the box.\n",
    "- Easy switching between strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee277191-f1a5-49cb-b80f-f4ca5ab06625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display logical devices\n",
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30ccaac2-7510-4979-8a56-ae3965c834e2",
   "metadata": {},
   "source": [
    "### One Device Strategy\n",
    "\n",
    "A distribution strategy for running on a single device. Device string identifier for the device on which the variables should be placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29117742-47bb-4f62-9ff4-e408958f5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to create a OneDeviceStrategy\n",
    "#strategy = tf.distribute.OneDeviceStrategy(device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34b265ab-1b8c-4543-ae8f-890a67f5cd9a",
   "metadata": {},
   "source": [
    "### Mirrored Strategy \n",
    "\n",
    "Supports synchronous distributed training on multiple GPUs on one machine. It creates one replica per GPU device. Each variable in the model is mirrored across all the replicas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3e8f3-868f-486a-a737-1dd0a8416383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to create a MirroredStrategy\n",
    "\n",
    "#strategy = tf.distribute.MirroredStrategy(devices=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f31f8230-ccd5-4561-91a7-f691167b86cf",
   "metadata": {},
   "source": [
    "### Multi-Worker Mirrored Strategy\n",
    "\n",
    "Multi-Worker MirroredStrategy is very similar to MirroredStrategy. It implements synchronous distributed training across multiple workers, each with potentially multiple GPUs. Similar to tf.distribute.MirroredStrategy, it creates copies of all variables in the model on each device across all workers.\n",
    "\n",
    "MultiWorkerMirroredStrategy has two implementations for cross-device communications. \n",
    "1. CommunicationImplementation.RING is RPC-based and supports both CPUs and GPUs. \n",
    "1. CommunicationImplementation.NCCL uses NCCL and provides state-of-art performance on GPUs but it doesn't support CPUs. \n",
    "1. CollectiveCommunication.AUTO defers the choice to Tensorflow. \n",
    "\n",
    "You can specify them in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b4884-b533-4f3c-9726-69a0042fc773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to create a Multi-worker Mirrored Strategy\n",
    "\n",
    "#communication_options = tf.distribute.experimental.CommunicationOptions(\n",
    "    # RING is RPC-based and supports both CPUs and GPUs.\n",
    "    #implementation=tf.distribute.experimental.CommunicationImplementation.RING)\n",
    "\n",
    "    # NCCL uses NCCL and provides state-of-art performance on GPUs but it doesn't support CPUs\n",
    "    #implementation=tf.distribute.experimental.CommunicationImplementation.NCCL)\n",
    "    \n",
    "    # AUTO defers the choice to Tensorflow.\n",
    "    #implementation=tf.distribute.experimental.CommunicationImplementation.AUTO)\n",
    "\n",
    "#strategy = tf.distribute.MultiWorkerMirroredStrategy(communication_options=communication_options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ca0541f-f9ba-4ddf-ab0a-9cf36109a829",
   "metadata": {},
   "source": [
    "## Search hyperparameters\n",
    "\n",
    "The Keras Tuner has four tuners available:\n",
    "1. RandomSearch\n",
    "1. Hyperband\n",
    "1. BayesianOptimization\n",
    "1. Sklearn. \n",
    "\n",
    "In this tutorial, you use the Hyperband tuner. \n",
    "\n",
    "The Hyperband tuning algorithm uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model. This is done using a sports championship style bracket. The algorithm trains a large number of models for a few epochs and carries forward only the top-performing half of models to the next round. \n",
    "\n",
    "To instantiate the Hyperband tuner, you must specify the hypermodel, the objective to optimize and the maximum number of epochs to train (max_epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c73aa40-8102-42eb-8a2a-a6eb0d3c14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "# open a strategy scope\n",
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    # Integer, the maximum number of epochs to train one model. It is recommended to set this to a value slightly higher than the expected epochs to convergence for your largest Model, and to use early stopping during training\n",
    "    max_epochs=5,\n",
    "    # Integer, the reduction factor for the number of epochs and number of models for each bracket. Defaults to 3.\n",
    "    factor=3,\n",
    "    # training strategy\n",
    "    #distribution_strategy=strategy,\n",
    "    # directory to save the hyperparameter trials\n",
    "    # TODO Update with a variable\n",
    "    directory=scratch_path + '/tune/model_hp',\n",
    "    # folder to save the hyperparameter trail outputs\n",
    "    project_name='hypertune',\n",
    "    #  If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. \n",
    "    # To disable this behavior, pass an additional overwrite=True argument while instantiating the tuner.\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43367a58-0043-4d9f-95dd-48e048ba6dcf",
   "metadata": {},
   "source": [
    "We’ll be using EarlyStopping to short circuit hyperparameter trials that are not performing well. Keep in mind that tuning hyperparameters is an extremely computationally expensive process, so if we can kill off poorly performing trials, we can save ourselves a bunch of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a5a0c3-5ad4-4af3-883c-c89db2ea393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop training when a monitored metric has stopped improving\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode=\"auto\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fa1a6f5-a2fb-4487-9a02-57370c11b171",
   "metadata": {},
   "source": [
    "This search will run for 10 Trials.\n",
    "- CPU: Best val_accuracy: 0.947070837020874  | Total elapsed time: 02h 11m 29s | Model: ?\n",
    "- GPU: Best val_accuracy: 0.872768342494964  | Total elapsed time: 00h 08m 44s | Sagemaker - Instance Type: ?\n",
    "- GPU: Best val_accuracy: 0.879129886627197  | Total elapsed time: 00h 59m 48s | Model: Tesla M10 (x4) | Driver Version: 525.60.13  |  CUDA Version: 12.0\n",
    "\n",
    "One a g4dn.16xlarge the learned values will be around: \n",
    "\n",
    "```\n",
    "[INFO] optimal number of filters in conv_1 layer: 96\n",
    "[INFO] optimal number of filters in conv_2 layer: 64\n",
    "[INFO] optimal number of filters in conv_3 layer: 256\n",
    "[INFO] optimal number of units in dense layer: 768\n",
    "[INFO] optimal learning rate: 0.0010\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ecff93-21cc-4bd4-acd8-873b66d6d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_ds, epochs=4, validation_data=validation_ds, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"[INFO] optimal number of filters in conv_1 layer: {}\".format(\n",
    "\tbest_hps.get(\"conv_1\")))\n",
    "print(\"[INFO] optimal number of filters in conv_2 layer: {}\".format(\n",
    "\tbest_hps.get(\"conv_2\")))\n",
    "print(\"[INFO] optimal number of filters in conv_3 layer: {}\".format(\n",
    "\tbest_hps.get(\"conv_3\")))\n",
    "print(\"[INFO] optimal number of units in dense layer: {}\".format(\n",
    "\tbest_hps.get(\"dense_units\")))\n",
    "print(\"[INFO] optimal learning rate: {:.4f}\".format(\n",
    "\tbest_hps.get(\"learning_rate\")))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91bdc351-986c-4b30-b882-7916c567b32e",
   "metadata": {},
   "source": [
    "## Fit a model\n",
    "\n",
    "Fit the model with the optimal hyperparameters and train it on the data for a desired number of epochs. This training cycle will run for 9 epochs resulting in an accuracy around ~0.98 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37c524-c591-44cd-90da-8ec410dd9f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "\n",
    "filename = '../reports/' + filename + '-score.csv'\n",
    "csv_logger = CSVLogger(filename, append=True, separator=';')\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=epochs,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    "    callbacks=[csv_logger]\n",
    ")\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7397fb89-0459-4003-9760-3a0ad92e5f3b",
   "metadata": {},
   "source": [
    "### Visualize the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa94d55-5623-427c-857d-90eda9832123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the resulting model architecture: https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model\n",
    "filename = os.getenv('FILENAME')\n",
    "\n",
    "to_file='../reports/' + filename + '_model_plot.png'\n",
    "tf.keras.utils.plot_model(model, show_shapes=True,to_file=to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe82d8-dbc0-46fd-8062-69dd35a4c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model\n",
    "to_file='../reports/' + filename + '_model_visual.png'\n",
    "visualkeras.layered_view(model, legend=True, draw_volume=True, to_file=to_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6b6b0f0-9baf-4611-be69-3d63c41cb83c",
   "metadata": {},
   "source": [
    "# Evaluate the model\n",
    "\n",
    "Next, compare how the model performs on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f34ff61-92d4-4f93-9df6-a9750100b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    verbose='auto',\n",
    "    sample_weight=None,\n",
    "    steps=None,\n",
    "    callbacks=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e46843f6-1787-4a36-9d08-fbbec3e39d0c",
   "metadata": {},
   "source": [
    "# Score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1ab9f-9abc-4770-993e-ade624368f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate(test_ds, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c366990b-4c9e-4aec-bdb5-2592d31f2ea2",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "A SavedModel is a directory containing serialized signatures and the state needed to run them, including variable values and vocabularies.\n",
    "\n",
    "```\n",
    "assets            directory contains files used by the TensorFlow graph\n",
    "keras_metadata.pb file  \n",
    "saved_model.pb    file stores the actual TensorFlow program, or model, and a set of named signatures for tensor I/O\n",
    "variables         directory contains a standard training checkpoint \n",
    "```\n",
    "\n",
    "There are 2 formats you can use to save an entire model to disk, the TensorFlow SavedModel format and the older Keras H5 format.\n",
    "\n",
    "For versioning, you typically generate several models made up of (code, data, config) that demands model versioning. \n",
    "\n",
    "`/parent-folder/project-name/VERSION_NUMBER/MAJOR.MINOR.PIPELINE.tf`\n",
    "\n",
    "Triton expects the following folder structure:\n",
    "\n",
    "`/parent-folder/project-name/VERSION_NUMBER/model.savedmodel`\n",
    "\n",
    "* `parent-folder` should be the root of s3 url, ex: `s3://bucket/parent-folder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3866b1da-074b-44b6-a5e5-121ba8ab626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: tf.saved_model.save(model, path_to_dir)\n",
    "model_path = \"../models/fingerprint/\" + \"1\" + \"/model.savedmodel\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952af3db-7208-425c-86fe-3cd6a1f9392d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
