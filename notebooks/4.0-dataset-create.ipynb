{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8c750b-1325-4adf-88e8-88a35b023ad0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e16e19-702e-46e4-824b-e99185dd4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 17:48:28.002473: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 17:48:28.124304: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-24 17:48:28.969094: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-24 17:48:28.969167: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-24 17:48:28.969177: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.1\n"
     ]
    }
   ],
   "source": [
    "# Install packages and frameworks\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# expecting 2.11\n",
    "# if 2.7, than logging errors will show \"Cleanup called...\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507f3f6e-6924-45ad-ba89-8aa21dc985e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SCRATCH=../scratch\n"
     ]
    }
   ],
   "source": [
    "# scratch directory is apart of the .gitignore to ensure it is not committed to git\n",
    "%env SCRATCH=../scratch\n",
    "! [ -e \"${SCRATCH}\" ] || mkdir -p \"${SCRATCH}\"\n",
    "\n",
    "scratch_path = os.environ.get('SCRATCH', './scratch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e973ed-5482-47f3-8885-d2efacefb33b",
   "metadata": {},
   "source": [
    "## Cleanup original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01522e96-54fa-402c-a7b8-08424e67c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists. Removing...\n"
     ]
    }
   ],
   "source": [
    "# path\n",
    "path = scratch_path + '/train'\n",
    "\n",
    "if os.path.exists(path) and os.path.isdir(path):\n",
    "    # Directory exists, execute your code here\n",
    "    print(\"Directory exists. Removing...\")\n",
    "    shutil.rmtree(path)\n",
    "    # Your code goes here\n",
    "else:\n",
    "    print(\"Directory does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72191ab9-2c62-4b1b-8ee0-25e6d2aed816",
   "metadata": {},
   "source": [
    "# Split the data into Train, Validation and Test\n",
    "\n",
    "Keras utility generates a dataset in tf.data.Dataset format from image files in a directory and infers the labels based on the parent folder. This utility will return a tf.data.Dataset that yields batches of images from the subdirectories left and right\n",
    "\n",
    "```\n",
    "train_lr/\n",
    "├── left/\n",
    "│   ├── a_image_1.jpg\n",
    "│   └── a_image_2.jpg\n",
    "└── right/\n",
    "    ├── b_image_1.jpg\n",
    "    └── b_image_2.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2724be93-afba-4144-b1b6-87b71e3db046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for consistency\n",
    "img_height = 96              # desired height\n",
    "img_width = 96               # desired width\n",
    "batch_size = 32              # batch inputs in 32\n",
    "seed_train_validation = 42   # Must be same for train_ds and val_ds\n",
    "validation_split = 0.3       # move 30% of the data into validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e0435-33b3-4cd0-b360-264e8be40ebb",
   "metadata": {},
   "source": [
    "## Create some new directories to save our prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a0c741-a0ce-480f-9a88-d80962d4f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p \"${SCRATCH}\"/tf_datasets/{train,validate,test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e044a4-86cb-455f-8bd2-0b3e657a10f9",
   "metadata": {},
   "source": [
    "## Create Train\n",
    "\n",
    "Train is the sample of data used to fit the model. Let's generate a tf.data.Dataset from the processed training examples and infer the labels from the directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ffe794-a4e4-41c2-8b28-bb6f995b4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order for keras to infer the labels, you cannot have any \"extra\" subdirectories that do not match your expected labels\n",
    "\n",
    "!rm -rf scratch_path + '/train_lr/.ipynb_checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc09534-6c80-4186-ab72-8afeffc70b31",
   "metadata": {},
   "source": [
    "The saved dataset is saved in multiple file \"shards\". By default, the dataset output is divided to shards in a round-robin fashion but custom sharding can be specified via the shard_func function. For example, you can save the dataset to using a single shard as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27aa4f66-8fd0-49d9-b011-578a6c00c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_shard_func(element):\n",
    "    return np.int64(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6dec14-fa70-40bd-9826-136705b63c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    scratch_path + '/train_lr',\n",
    "    labels='inferred',\n",
    "    label_mode = \"categorical\", \n",
    "    class_names=['left','right'],\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True, \n",
    "    seed=seed_train_validation,\n",
    "    validation_split=validation_split,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# save the dataset\n",
    "dir = scratch_path + \"/tf_datasets/train\"\n",
    "tf.data.Dataset.save(train_ds,\n",
    "                     dir, \n",
    "                     #compression=None,\n",
    "                     #shard_func=custom_shard_func,\n",
    "                     checkpoint_args=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f60f83-8517-4739-8c81-aea2a1bc19ce",
   "metadata": {},
   "source": [
    "## Create Validation\n",
    "\n",
    "Validation is the sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The evaluation becomes more biased as skill on the validation dataset is incorporated into the model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eead56f-71bd-4062-a334-f3b4cb17ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the validation dataset\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    scratch_path + '/train_lr',\n",
    "    labels='inferred',\n",
    "    label_mode = \"categorical\", \n",
    "    class_names=['left','right'],\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True, \n",
    "    seed=seed_train_validation,\n",
    "    validation_split=validation_split,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# save the dataset\n",
    "dir = scratch_path + \"/tf_datasets/validate\"\n",
    "tf.data.Dataset.save(validation_ds,\n",
    "                     dir, \n",
    "                     #compression=None,\n",
    "                     #shard_func=custom_shard_func,\n",
    "                     checkpoint_args=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd887e-0048-4e1e-a036-7788571a541f",
   "metadata": {},
   "source": [
    "## Create Test\n",
    "\n",
    "The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215771a6-fb81-499f-805a-3387163fb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the test dataset\n",
    "test_ds = validation_ds.take(16)\n",
    "validation_ds = validation_ds.skip(16)\n",
    "\n",
    "# save the datasets\n",
    "dir = scratch_path + \"/tf_datasets/test\"\n",
    "tf.data.Dataset.save(test_ds,\n",
    "                     dir, \n",
    "                     #compression=None,\n",
    "                     #shard_func=custom_shard_func,\n",
    "                     checkpoint_args=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee5113-9c59-47cf-b151-2ba0a6067d91",
   "metadata": {},
   "source": [
    "You now have a train, validation, and test dataset written to a directory. tf.data.Dataset.save() is used to save the dataset to the specified save_dir. Make sure to provide a valid path to the directory where you want to save the dataset. The dataset will be saved in a sharded file format.\n",
    "\n",
    "Later, if you want to load the saved dataset, you can use tf.data.Dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37aaf71-aeeb-4ce6-8bc9-d63b9eca2690",
   "metadata": {},
   "source": [
    "## Print the Dataset batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ab2f2-b822-4e99-96c9-2eb0808d5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserves 393 batches training\n",
    "print('70% for training -->', train_ds.cardinality())\n",
    "# reserves 164 batches validation\n",
    "print('20% for validating -->', validation_ds.cardinality())\n",
    "# reserves 5 batches testing\n",
    "print('10% for testing -->', test_ds.cardinality())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d177737-e37e-4653-827c-2c5fd0324fb9",
   "metadata": {},
   "source": [
    "## Print Inferred Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ac758-4c0a-4b5b-9e20-8bbab5bcb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the class names inferred from the training dataset\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a169603c-766e-4089-9e00-4d2b38a5a1c8",
   "metadata": {},
   "source": [
    "# Apply augmentation\n",
    "When you don't have a large image dataset or when your images are all set in a single direction like ours are, it's a good practice to artificially introduce sample diversity by applying random, yet realistic, transformations to the training images, such as rotation and horizontal flipping. This helps expose the model to different aspects of the training data and reduce over-fitting.\n",
    "\n",
    "Learn more https://www.tensorflow.org/tutorials/images/data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d15064-9c01-48ed-a4fd-41842cceeb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "\n",
    "  # randomly rotates images during training\n",
    "  tf.keras.layers.RandomRotation(\n",
    "    # a float represented as fraction of 2 Pi, or a tuple of size 2 representing lower and upper bound for rotating clockwise and counter-clockwise. \n",
    "    0.2,                     # A positive values means rotating counter clock-wise, while a negative value means clock-wise. \n",
    "    fill_mode='constant',    # Points outside the boundaries of the input are filled according to the given mode (one of {\"constant\", \"reflect\", \"wrap\", \"nearest\"}).\n",
    "    interpolation='nearest', # Supported values: \"nearest\", \"bilinear\".\n",
    "    seed=None,               # Integer. Used to create a random seed.\n",
    "    fill_value=0.0           # the value to be filled outside the boundaries when fill_mode=\"constant\".\n",
    "),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8b992-0e57-482e-8ebf-0127e65b2a47",
   "metadata": {},
   "source": [
    "for image, _ in train_ds.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[2]\n",
    "  for i in range(10):\n",
    "    ax = plt.subplot(5, 5, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 1, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8c6c3-3ef2-403a-989d-84e98cc6393b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
