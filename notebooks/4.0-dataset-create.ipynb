{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8c750b-1325-4adf-88e8-88a35b023ad0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41e16e19-702e-46e4-824b-e99185dd4b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.1\n"
     ]
    }
   ],
   "source": [
    "# Install packages and frameworks\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib as plt\n",
    "\n",
    "# expecting 2.11\n",
    "# if 2.7, than logging errors will show \"Cleanup called...\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507f3f6e-6924-45ad-ba89-8aa21dc985e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SCRATCH=../scratch\n"
     ]
    }
   ],
   "source": [
    "# scratch directory is apart of the .gitignore to ensure it is not committed to git\n",
    "%env SCRATCH=../scratch\n",
    "! [ -e \"${SCRATCH}\" ] || mkdir -p \"${SCRATCH}\"\n",
    "\n",
    "scratch_path = os.environ.get('SCRATCH', './scratch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e973ed-5482-47f3-8885-d2efacefb33b",
   "metadata": {},
   "source": [
    "## Cleanup original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01522e96-54fa-402c-a7b8-08424e67c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory does not exist.\n"
     ]
    }
   ],
   "source": [
    "# path\n",
    "path = scratch_path + '/train'\n",
    "\n",
    "if os.path.exists(path) and os.path.isdir(path):\n",
    "    # Directory exists, execute your code here\n",
    "    print(\"Directory exists. Removing...\")\n",
    "    shutil.rmtree(path)\n",
    "    # Your code goes here\n",
    "else:\n",
    "    print(\"Directory does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72191ab9-2c62-4b1b-8ee0-25e6d2aed816",
   "metadata": {},
   "source": [
    "# Split the data into Train, Validation and Test\n",
    "\n",
    "Keras utility generates a dataset in tf.data.Dataset format from image files in a directory and infers the labels based on the parent folder. This utility will return a tf.data.Dataset that yields batches of images from the subdirectories left and right\n",
    "\n",
    "```\n",
    "train_lr/\n",
    "├── left/\n",
    "│   ├── a_image_1.jpg\n",
    "│   └── a_image_2.jpg\n",
    "└── right/\n",
    "    ├── b_image_1.jpg\n",
    "    └── b_image_2.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2724be93-afba-4144-b1b6-87b71e3db046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for consistency\n",
    "img_height = 96              # desired height\n",
    "img_width = 96               # desired width\n",
    "batch_size = 32              # batch inputs in 32\n",
    "seed_train_validation = 42   # Must be same for train_ds and val_ds\n",
    "validation_split = 0.3       # move 30% of the data into validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e0435-33b3-4cd0-b360-264e8be40ebb",
   "metadata": {},
   "source": [
    "## Create some new directories to save our prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a0c741-a0ce-480f-9a88-d80962d4f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p \"${SCRATCH}\"/tf_datasets/{train,validate,test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e044a4-86cb-455f-8bd2-0b3e657a10f9",
   "metadata": {},
   "source": [
    "## Create Train\n",
    "\n",
    "Train is the sample of data used to fit the model. Let's generate a tf.data.Dataset from the processed training examples and infer the labels from the directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ffe794-a4e4-41c2-8b28-bb6f995b4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order for keras to infer the labels, you cannot have any \"extra\" subdirectories that do not match your expected labels\n",
    "\n",
    "!rm -rf scratch_path + '/train_lr/.ipynb_checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc09534-6c80-4186-ab72-8afeffc70b31",
   "metadata": {},
   "source": [
    "The saved dataset is saved in multiple file \"shards\". By default, the dataset output is divided to shards in a round-robin fashion but custom sharding can be specified via the shard_func function. For example, you can save the dataset to using a single shard as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27aa4f66-8fd0-49d9-b011-578a6c00c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_shard_func(element):\n",
    "    return np.int64(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce6dec14-fa70-40bd-9826-136705b63c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17955 files belonging to 2 classes.\n",
      "Using 12569 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 21:49:36.993248: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-30 21:49:37.022134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-30 21:49:37.025491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-30 21:49:37.028912: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 21:49:37.031075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-30 21:49:37.034029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-30 21:49:37.036725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-30 21:49:37.787423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-30 21:49:37.789327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-30 21:49:37.790922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-30 21:49:37.792455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13595 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1b.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# create the training dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    scratch_path + '/train_lr',\n",
    "    labels='inferred',\n",
    "    label_mode = \"categorical\", \n",
    "    class_names=['left','right'],\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True, \n",
    "    seed=seed_train_validation,\n",
    "    validation_split=validation_split,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# save the dataset\n",
    "dir = scratch_path + \"/tf_datasets/train\"\n",
    "tf.data.Dataset.save(train_ds,\n",
    "                     dir, \n",
    "                     #compression=None,\n",
    "                     #shard_func=custom_shard_func,\n",
    "                     checkpoint_args=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f60f83-8517-4739-8c81-aea2a1bc19ce",
   "metadata": {},
   "source": [
    "## Create Validation\n",
    "\n",
    "Validation is the sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The evaluation becomes more biased as skill on the validation dataset is incorporated into the model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eead56f-71bd-4062-a334-f3b4cb17ad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17955 files belonging to 2 classes.\n",
      "Using 5386 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# create the validation dataset\n",
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    scratch_path + '/train_lr',\n",
    "    labels='inferred',\n",
    "    label_mode = \"categorical\", \n",
    "    class_names=['left','right'],\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True, \n",
    "    seed=seed_train_validation,\n",
    "    validation_split=validation_split,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# save the dataset\n",
    "dir = scratch_path + \"/tf_datasets/validate\"\n",
    "tf.data.Dataset.save(validation_ds,\n",
    "                     dir, \n",
    "                     #compression=None,\n",
    "                     #shard_func=custom_shard_func,\n",
    "                     checkpoint_args=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd887e-0048-4e1e-a036-7788571a541f",
   "metadata": {},
   "source": [
    "## Create Test\n",
    "\n",
    "The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "215771a6-fb81-499f-805a-3387163fb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the test dataset\n",
    "test_ds = validation_ds.take(16)\n",
    "validation_ds = validation_ds.skip(16)\n",
    "\n",
    "# save the datasets\n",
    "dir = scratch_path + \"/tf_datasets/test\"\n",
    "tf.data.Dataset.save(test_ds,\n",
    "                     dir, \n",
    "                     #compression=None,\n",
    "                     #shard_func=custom_shard_func,\n",
    "                     checkpoint_args=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee5113-9c59-47cf-b151-2ba0a6067d91",
   "metadata": {},
   "source": [
    "You now have a train, validation, and test dataset written to a directory. tf.data.Dataset.save() is used to save the dataset to the specified save_dir. Make sure to provide a valid path to the directory where you want to save the dataset. The dataset will be saved in a sharded file format.\n",
    "\n",
    "Later, if you want to load the saved dataset, you can use tf.data.Dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37aaf71-aeeb-4ce6-8bc9-d63b9eca2690",
   "metadata": {},
   "source": [
    "## Print the Dataset batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe1ab2f2-b822-4e99-96c9-2eb0808d5f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70% for training --> tf.Tensor(393, shape=(), dtype=int64)\n",
      "20% for validating --> tf.Tensor(153, shape=(), dtype=int64)\n",
      "10% for testing --> tf.Tensor(16, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# reserves 393 batches training\n",
    "print('70% for training -->', train_ds.cardinality())\n",
    "# reserves 164 batches validation\n",
    "print('20% for validating -->', validation_ds.cardinality())\n",
    "# reserves 5 batches testing\n",
    "print('10% for testing -->', test_ds.cardinality())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d177737-e37e-4653-827c-2c5fd0324fb9",
   "metadata": {},
   "source": [
    "## Print Inferred Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a5ac758-4c0a-4b5b-9e20-8bbab5bcb091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['left', 'right']\n"
     ]
    }
   ],
   "source": [
    "# display the class names inferred from the training dataset\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a169603c-766e-4089-9e00-4d2b38a5a1c8",
   "metadata": {},
   "source": [
    "# Apply augmentation\n",
    "When you don't have a large image dataset or when your images are all set in a single direction like ours are, it's a good practice to artificially introduce sample diversity by applying random, yet realistic, transformations to the training images, such as rotation and horizontal flipping. This helps expose the model to different aspects of the training data and reduce over-fitting.\n",
    "\n",
    "Learn more https://www.tensorflow.org/tutorials/images/data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9d15064-9c01-48ed-a4fd-41842cceeb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "\n",
    "  # randomly rotates images during training\n",
    "  tf.keras.layers.RandomRotation(\n",
    "    # a float represented as fraction of 2 Pi, or a tuple of size 2 representing lower and upper bound for rotating clockwise and counter-clockwise. \n",
    "    0.2,                     # A positive values means rotating counter clock-wise, while a negative value means clock-wise. \n",
    "    fill_mode='constant',    # Points outside the boundaries of the input are filled according to the given mode (one of {\"constant\", \"reflect\", \"wrap\", \"nearest\"}).\n",
    "    interpolation='nearest', # Supported values: \"nearest\", \"bilinear\".\n",
    "    seed=None,               # Integer. Used to create a random seed.\n",
    "    fill_value=0.0           # the value to be filled outside the boundaries when fill_mode=\"constant\".\n",
    "),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1f4d147-7188-4143-90e9-c004994603f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'figure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, _ \u001b[38;5;129;01min\u001b[39;00m train_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m   \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      3\u001b[0m   first_image \u001b[38;5;241m=\u001b[39m image[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/matplotlib/_api/__init__.py:224\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'figure'"
     ]
    }
   ],
   "source": [
    "for image, _ in train_ds.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[2]\n",
    "  for i in range(10):\n",
    "    ax = plt.subplot(5, 5, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 1, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8c6c3-3ef2-403a-989d-84e98cc6393b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
