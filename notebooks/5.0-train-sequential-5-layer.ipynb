{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb86f8e1-b38b-4d0c-92b5-257c657ce304",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0685747-4565-4cf5-ae05-ed5d7ea051da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 04:56:31.587435: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 04:56:31.708577: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-24 04:56:32.586155: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-24 04:56:32.586230: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-24 04:56:32.586240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.1\n"
     ]
    }
   ],
   "source": [
    "# Install packages and frameworks\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# expecting 2.11\n",
    "# if 2.7, than logging errors will show \"Cleanup called...\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba71e1f6-f29c-4c35-8a92-a60c8851fd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SCRATCH=../scratch\n"
     ]
    }
   ],
   "source": [
    "# scratch directory is apart of the .gitignore to ensure it is not committed to git\n",
    "%env SCRATCH=../scratch\n",
    "! [ -e \"${SCRATCH}\" ] || mkdir -p \"${SCRATCH}\"\n",
    "\n",
    "scratch_path = os.environ.get('SCRATCH', './scratch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edfc60d-2aec-4516-8cb7-8837441b8391",
   "metadata": {},
   "source": [
    "# Load the saved datasets\n",
    "\n",
    "The TFRecord format is a simple format for storing a sequence of binary records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165835a8-5f4b-4c1d-9dfa-461e290b9b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 04:56:34.466852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:34.468781: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:34.496063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:34.497907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:34.499623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:34.501315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:34.503439: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 04:56:34.931424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:34.933120: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:34.934919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:34.936409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:34.938094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:34.939582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:35.940452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:35.942237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:35.944152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:35.945639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:35.947335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:35.948819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 54 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1d.0, compute capability: 7.5\n",
      "2023-05-24 04:56:35.949298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 04:56:35.950976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 54 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = scratch_path + '/tf_datasets/train/'\n",
    "train_ds = tf.data.Dataset.load(path)\n",
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "368c217f-f53f-4700-8fdc-19a14528a37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = scratch_path + '/tf_datasets/validate/'\n",
    "validation_ds = tf.data.Dataset.load(path)\n",
    "validation_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f42449-1ee8-4a92-a2af-a8d484843a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = scratch_path + '/tf_datasets/test/'\n",
    "test_ds = tf.data.Dataset.load(path)\n",
    "test_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b7454a-3458-4213-9265-dd25d88f1466",
   "metadata": {},
   "source": [
    "## Configure the datasets for performance\n",
    "\n",
    "Let's make sure to use buffered prefetching so we can yield data from disk without having I/O become blocking. These are two important methods you should use when loading data.\n",
    "\n",
    "1. `Caching` a dataset, either in memory or on local storage. This will save some operations (like file opening and data reading) from being executed during each epoch.\n",
    "1. `Prefetching` overlaps the preprocessing and model execution of a training step. While the model is executing training step s, the input pipeline is reading the data for step s+1. Doing so reduces the step time to the maximum (as opposed to the sum) of the training and the time it takes to extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd87b5b-a9c6-43ff-b6c3-1004627a9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da87c9-0c6b-49af-ae0e-c0f3b98515a0",
   "metadata": {},
   "source": [
    "# Check the device spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c352932-39d4-4ea2-adc8-c761506bf7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display physical devices\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ee4bcd-e215-414e-b73b-67c9bd65a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  example, single device\n",
    "#device=\"/cpu:0\"\n",
    "device=\"/GPU:0\"\n",
    "\n",
    "strategy = tf.distribute.OneDeviceStrategy(device=device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc5eed84-f581-4bdd-8770-3cb3d0b405ec",
   "metadata": {},
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "#  when keras run with gpu, it uses almost all vram. So we needed to give memory_limit for each notebook as shown below\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232d3709-db26-4a83-ac98-a36013a86e76",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443bfbbf-3f3f-45a2-9586-85bf8d04657d",
   "metadata": {},
   "source": [
    "## Set some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d699ebcd-4965-416a-93a6-654e49fd0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for consistency\n",
    "img_height = 96              # desired height\n",
    "img_width = 96               # desired width\n",
    "batch_size = 32              # batch inputs in 32\n",
    "seed_train_validation = 42   # Must be same for train_ds and val_ds\n",
    "validation_split = 0.3       # move 30% of the data into validation\n",
    "class_names = ['left', 'right']\n",
    "\n",
    "dataFormat=\"channels_last\"\n",
    "num_classes = len(class_names)\n",
    "inputShape=(img_height, img_width, 1)\n",
    "chanDim = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32f43e-eb02-4411-b593-99e860cdd4e0",
   "metadata": {},
   "source": [
    "tf.keras models are optimized to make predictions on a batch, or collection, of examples at once. Accordingly, even though you're using a single image, you need to add it to a list:\n",
    "\n",
    "## Setup the layers\n",
    "\n",
    "The Sequential model consists of three convolution blocks (tf.keras.layers.Conv2D) with a max pooling layer (tf.keras.layers.MaxPooling2D) in each of them. There's a fully-connected layer (tf.keras.layers.Dense) with 128 units on top of it that is activated by a ReLU activation function ('relu'). This model has not been tuned in any way—the goal is to show you the mechanics using the datasets you just created. To learn more about image classification, visit the Image classification tutorial.\n",
    "\n",
    "Here's an example of Python code using Keras to create a sequential classification model that accepts 96x96x1 input images.\n",
    "\n",
    "In this example, we start with three convolutional layers, each followed by a max pooling layer to downsample the input. Then, we flatten the output from the convolutional layers and add two fully connected layers. Finally, we add an output layer with the number of classes and compile the model using an optimizer (e.g., Adam) and a loss function (e.g., categorical cross-entropy).\n",
    "\n",
    "Make sure to replace num_classes with the actual number of classes in your classification problem.\n",
    "```\n",
    "import tensorflow as tf    \n",
    "\n",
    "model = tf.keras.Model(...)\n",
    "\n",
    "# Run training on GPU\n",
    "with tf.device('/gpu:0'):\n",
    "    model.fit(...)\n",
    "\n",
    "# Run inference on CPU\n",
    "with tf.device('/cpu:0'):\n",
    "    model.predict(...)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122651a9-8379-408c-9bae-1d018f0b496d",
   "metadata": {},
   "source": [
    "# Set up the layers\n",
    "The basic building block of a neural network is the layer. Layers extract representations from the data fed into them. Hopefully, these representations are meaningful for the problem at hand.\n",
    "\n",
    "Most of deep learning consists of chaining together simple layers. Most layers, such as tf.keras.layers.Dense, have parameters that are learned during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f6b0d3-6ade-4496-b898-4553258b2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "\n",
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=inputShape),\n",
    "        tf.keras.layers.Reshape(target_shape=inputShape),\n",
    "        tf.keras.layers.Conv2D(96, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(96, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(96, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(96, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(96, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes),\n",
    "        tf.keras.layers.Softmax()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc19a77c-2cee-49e4-9da7-3841f2b320ec",
   "metadata": {},
   "source": [
    "# Compile the model\n",
    "\n",
    "Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n",
    "\n",
    "Loss function —This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n",
    "Optimizer —This is how the model is updated based on the data it sees and its loss function.\n",
    "Metrics —Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0547dca-a170-49e6-a1fe-198a5da84176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 96, 96, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 94, 94, 96)        960       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 47, 47, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 45, 45, 96)        83040     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 22, 22, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 96)        83040     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 96)          83040     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 96)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 2, 2, 96)          83040     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 1, 1, 96)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               24832     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 358,466\n",
      "Trainable params: 358,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(\n",
    "                  from_logits=False,\n",
    "                  label_smoothing=0.0,\n",
    "                  axis=-1,\n",
    "                  #reduction=losses_utils.ReductionV2.AUTO,\n",
    "                  name='categorical_crossentropy'),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ee8cf-58e1-46aa-95ba-82d89736d9ea",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Training the neural network model requires the following steps:\n",
    "\n",
    "Feed the training data to the model. In this example, the training data is in the train_images and train_labels arrays.\n",
    "The model learns to associate images and labels.\n",
    "You ask the model to make predictions about a test set—in this example, the test_images array.\n",
    "Verify that the predictions match the labels from the test_labels array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f24a68a-4ac5-47fe-a429-4852569d80b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 04:56:36.231364: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"LoadDataset/_1\"\n",
      "op: \"LoadDataset\"\n",
      "input: \"Const/_0\"\n",
      "attr {\n",
      "  key: \"Treader_func_args\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 393\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"compression\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 96\n",
      "        }\n",
      "        dim {\n",
      "          size: 96\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 2\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"reader_func\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_load_lambda_14\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 04:56:47.494897: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 103.55MiB (rounded to 108576768)requested by op sequential/conv2d/Relu\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-05-24 04:56:47.494996: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-05-24 04:56:47.495027: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 29, Chunks in use: 29. 7.2KiB allocated for chunks. 7.2KiB in use in bin. 912B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495051: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 15, Chunks in use: 15. 7.5KiB allocated for chunks. 7.5KiB in use in bin. 5.6KiB client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495073: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 4, Chunks in use: 4. 4.2KiB allocated for chunks. 4.2KiB in use in bin. 4.0KiB client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495097: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 6, Chunks in use: 6. 16.5KiB allocated for chunks. 16.5KiB in use in bin. 16.1KiB client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495119: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495138: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495158: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495177: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495201: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 2, Chunks in use: 2. 192.0KiB allocated for chunks. 192.0KiB in use in bin. 192.0KiB client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495224: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 178.2KiB allocated for chunks. 178.2KiB in use in bin. 96.0KiB client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495246: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 12, Chunks in use: 12. 3.83MiB allocated for chunks. 3.83MiB in use in bin. 3.80MiB client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495274: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495295: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 2. 2.25MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495315: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495334: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495353: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495372: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495393: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 47.90MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495413: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495432: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495451: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-24 04:56:47.495473: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 103.55MiB was 64.00MiB, Chunk State: \n",
      "2023-05-24 04:56:47.495492: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 57016320\n",
      "2023-05-24 04:56:47.495516: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104000000 of size 1280 next 1\n",
      "2023-05-24 04:56:47.495535: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104000500 of size 256 next 2\n",
      "2023-05-24 04:56:47.495552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104000600 of size 256 next 3\n",
      "2023-05-24 04:56:47.495597: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104000700 of size 256 next 4\n",
      "2023-05-24 04:56:47.495615: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104000800 of size 256 next 5\n",
      "2023-05-24 04:56:47.495632: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104000900 of size 256 next 7\n",
      "2023-05-24 04:56:47.495650: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104000a00 of size 512 next 8\n",
      "2023-05-24 04:56:47.495670: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104000c00 of size 256 next 6\n",
      "2023-05-24 04:56:47.495688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104000d00 of size 256 next 9\n",
      "2023-05-24 04:56:47.495705: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104000e00 of size 512 next 14\n",
      "2023-05-24 04:56:47.495723: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104001000 of size 512 next 17\n",
      "2023-05-24 04:56:47.495740: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104001200 of size 512 next 19\n",
      "2023-05-24 04:56:47.495757: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104001400 of size 512 next 21\n",
      "2023-05-24 04:56:47.495792: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104001600 of size 256 next 12\n",
      "2023-05-24 04:56:47.495809: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104001700 of size 256 next 13\n",
      "2023-05-24 04:56:47.495829: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104001800 of size 1024 next 25\n",
      "2023-05-24 04:56:47.495847: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104001c00 of size 256 next 23\n",
      "2023-05-24 04:56:47.495864: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104001d00 of size 256 next 24\n",
      "2023-05-24 04:56:47.495882: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104001e00 of size 512 next 40\n",
      "2023-05-24 04:56:47.495899: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104002000 of size 512 next 41\n",
      "2023-05-24 04:56:47.495920: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104002200 of size 512 next 43\n",
      "2023-05-24 04:56:47.495938: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104002400 of size 512 next 44\n",
      "2023-05-24 04:56:47.495955: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104002600 of size 512 next 10\n",
      "2023-05-24 04:56:47.495974: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104002800 of size 3584 next 11\n",
      "2023-05-24 04:56:47.495997: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104003600 of size 256 next 29\n",
      "2023-05-24 04:56:47.496014: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104003700 of size 256 next 28\n",
      "2023-05-24 04:56:47.496032: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104003800 of size 256 next 30\n",
      "2023-05-24 04:56:47.496049: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104003900 of size 256 next 33\n",
      "2023-05-24 04:56:47.496069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104003a00 of size 256 next 34\n",
      "2023-05-24 04:56:47.496087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104003b00 of size 256 next 35\n",
      "2023-05-24 04:56:47.496104: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104003c00 of size 256 next 36\n",
      "2023-05-24 04:56:47.496121: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104003d00 of size 256 next 37\n",
      "2023-05-24 04:56:47.496142: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104003e00 of size 256 next 31\n",
      "2023-05-24 04:56:47.496159: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104003f00 of size 2048 next 32\n",
      "2023-05-24 04:56:47.496178: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104004700 of size 3584 next 38\n",
      "2023-05-24 04:56:47.496196: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104005500 of size 3584 next 39\n",
      "2023-05-24 04:56:47.496216: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104006300 of size 512 next 47\n",
      "2023-05-24 04:56:47.496234: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104006500 of size 512 next 50\n",
      "2023-05-24 04:56:47.496251: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104006700 of size 512 next 51\n",
      "2023-05-24 04:56:47.496268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104006900 of size 512 next 54\n",
      "2023-05-24 04:56:47.496289: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104006b00 of size 512 next 55\n",
      "2023-05-24 04:56:47.496307: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104006d00 of size 182528 next 27\n",
      "2023-05-24 04:56:47.496324: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104033600 of size 98304 next 26\n",
      "2023-05-24 04:56:47.496345: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110404b600 of size 368640 next 16\n",
      "2023-05-24 04:56:47.496364: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11040a5600 of size 331776 next 15\n",
      "2023-05-24 04:56:47.496381: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11040f6600 of size 331776 next 18\n",
      "2023-05-24 04:56:47.496405: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104147600 of size 331776 next 20\n",
      "2023-05-24 04:56:47.496412: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104198600 of size 331776 next 22\n",
      "2023-05-24 04:56:47.496419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11041e9600 of size 331776 next 42\n",
      "2023-05-24 04:56:47.496425: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110423a600 of size 331776 next 45\n",
      "2023-05-24 04:56:47.496433: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110428b600 of size 331776 next 46\n",
      "2023-05-24 04:56:47.496440: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11042dc600 of size 331776 next 48\n",
      "2023-05-24 04:56:47.496446: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110432d600 of size 331776 next 49\n",
      "2023-05-24 04:56:47.496453: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110437e600 of size 331776 next 52\n",
      "2023-05-24 04:56:47.496461: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f11043cf600 of size 331776 next 53\n",
      "2023-05-24 04:56:47.496468: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104420600 of size 98304 next 56\n",
      "2023-05-24 04:56:47.496475: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104438600 of size 1024 next 57\n",
      "2023-05-24 04:56:47.496481: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104438a00 of size 1024 next 58\n",
      "2023-05-24 04:56:47.496490: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104438e00 of size 2048 next 59\n",
      "2023-05-24 04:56:47.496496: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104439600 of size 2048 next 60\n",
      "2023-05-24 04:56:47.496503: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104439e00 of size 256 next 61\n",
      "2023-05-24 04:56:47.496510: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f1104439f00 of size 256 next 62\n",
      "2023-05-24 04:56:47.496517: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110443a000 of size 256 next 63\n",
      "2023-05-24 04:56:47.496525: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110443a100 of size 256 next 64\n",
      "2023-05-24 04:56:47.496531: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110443a200 of size 256 next 65\n",
      "2023-05-24 04:56:47.496538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110443a300 of size 1179648 next 66\n",
      "2023-05-24 04:56:47.496546: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110455a300 of size 256 next 67\n",
      "2023-05-24 04:56:47.496553: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110455a400 of size 256 next 68\n",
      "2023-05-24 04:56:47.496571: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110455a500 of size 256 next 69\n",
      "2023-05-24 04:56:47.496578: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110455a600 of size 256 next 70\n",
      "2023-05-24 04:56:47.496585: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f110455a700 of size 1179648 next 71\n",
      "2023-05-24 04:56:47.496594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f110467a700 of size 50223360 next 18446744073709551615\n",
      "2023-05-24 04:56:47.496602: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-05-24 04:56:47.496611: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 29 Chunks of size 256 totalling 7.2KiB\n",
      "2023-05-24 04:56:47.496620: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 15 Chunks of size 512 totalling 7.5KiB\n",
      "2023-05-24 04:56:47.496627: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 1024 totalling 3.0KiB\n",
      "2023-05-24 04:56:47.496634: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-05-24 04:56:47.496642: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 2048 totalling 6.0KiB\n",
      "2023-05-24 04:56:47.496649: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 3584 totalling 10.5KiB\n",
      "2023-05-24 04:56:47.496659: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 98304 totalling 192.0KiB\n",
      "2023-05-24 04:56:47.496666: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 182528 totalling 178.2KiB\n",
      "2023-05-24 04:56:47.496675: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 11 Chunks of size 331776 totalling 3.48MiB\n",
      "2023-05-24 04:56:47.496683: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 368640 totalling 360.0KiB\n",
      "2023-05-24 04:56:47.496690: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 1179648 totalling 2.25MiB\n",
      "2023-05-24 04:56:47.496697: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 6.48MiB\n",
      "2023-05-24 04:56:47.496707: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 57016320 memory_limit_: 57016320 available bytes: 0 curr_region_allocation_bytes_: 114032640\n",
      "2023-05-24 04:56:47.496718: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                        57016320\n",
      "InUse:                         6792960\n",
      "MaxInUse:                      6792960\n",
      "NumAllocs:                         111\n",
      "MaxAllocSize:                  1179648\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-05-24 04:56:47.496731: W tensorflow/tsl/framework/bfc_allocator.cc:492] ************________________________________________________________________________________________\n",
      "2023-05-24 04:56:47.496768: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops_fused_impl.h:766 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,96,94,94] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/conv2d/Relu' defined at (most recent call last):\n    File \"/usr/lib64/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib64/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/app-root/lib64/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/opt/app-root/lib64/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib64/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib64/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib64/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3832/1014401378.py\", line 2, in <module>\n      model.fit(train_ds, epochs=10, validation_data=validation_ds)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/backend.py\", line 5369, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential/conv2d/Relu'\nOOM when allocating tensor with shape[32,96,94,94] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/conv2d/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1841]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/conv2d/Relu' defined at (most recent call last):\n    File \"/usr/lib64/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib64/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/app-root/lib64/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/opt/app-root/lib64/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib64/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib64/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib64/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_3832/1014401378.py\", line 2, in <module>\n      model.fit(train_ds, epochs=10, validation_data=validation_ds)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/backend.py\", line 5369, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential/conv2d/Relu'\nOOM when allocating tensor with shape[32,96,94,94] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/conv2d/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1841]"
     ]
    }
   ],
   "source": [
    "with tf.device(device):\n",
    "    model.fit(train_ds, epochs=10, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6b0f0-9baf-4611-be69-3d63c41cb83c",
   "metadata": {},
   "source": [
    "# Evaluate accuracy\n",
    "\n",
    "Next, compare how the model performs on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f34ff61-92d4-4f93-9df6-a9750100b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46843f6-1787-4a36-9d08-fbbec3e39d0c",
   "metadata": {},
   "source": [
    "# Print Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fdc063-7afd-4b79-bfdf-6f9ec5480104",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1ab9f-9abc-4770-993e-ade624368f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
