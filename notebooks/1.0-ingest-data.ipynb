{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53bf1b9c-0994-41ea-be22-c887d5c6aedd",
   "metadata": {},
   "source": [
    "# Fingerprint Left or Right Hand Prediction\n",
    "\n",
    "## About the data\n",
    "Sokoto Coventry Fingerprint Dataset (SOCOFing) is a biometric fingerprint database designed for academic research purposes. SOCOFing is made up of 6,000 fingerprint images from 600 African subjects and contains unique attributes such as labels for gender, hand and finger name as well as synthetically altered versions with three different levels of alteration for obliteration, central rotation, and z-cut. For a complete formal description and usage policy please refer to the following paper: https://arxiv.org/abs/1807.10609.\n",
    "\n",
    "## About the notebook\n",
    "The intention of this notebook is to demonstrate steps from data ingestion to model saving that provides an accurate enough model that predicts if a fingerprint comes from a left or right hand. Coupled with other models that accurately predict finger and gender is valuable when matching against other identifiable information.\n",
    "\n",
    "1. *Data Ingestion* [from object storage](#working-with-s3-buckets)\n",
    "1. *Dataset preparation* (infer labels, splitting, augmenting, optimizing)\n",
    "1. *Model Development* from scratch and *Training Strategies* (one device, mirrored, multi-worker mirrored)\n",
    "1. *Model Performance* Hyperparameter Tuning strategies (RandomSearch, Hyperband, BayesianOptimization, Sklearn)\n",
    "1. *Model Serialization* to object storage\n",
    "1. *Prediction Sampling*\n",
    "\n",
    "### Notebook Tested Requirements\n",
    "\n",
    "|Notebook origin|Notebook Customization|Instance Type|Kernel|TensorFlow|Runtime|\n",
    "|:-------|:-------|:-------|:-------|:-------|:-------|\n",
    "|SageMaker Notebook Instances|[from GitHub](https://github.com/redhat-na-ssa/demo-rosa-sagemaker/blob/main/sagemaker/lifecycle-from-github.sh)|ml.m5.4xlarge (vCPU: 16, RAM: 64 GiB)|conda_tensorflow2_p310|2.11|~120 minutes|\n",
    "|SageMaker Notebook Instances|[from GitHub](https://github.com/redhat-na-ssa/demo-rosa-sagemaker/blob/main/sagemaker/lifecycle-from-github.sh)|ml.p3.8xlarge (vCPU: 32, RAM: 244 GiB)|conda_tensorflow2_p310|2.11|~15 minutes|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "abfa098c-5402-4108-9a5d-4ea778fab9d7",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "If this is your first time running the notebook, you may need to restart the kernel after the Tensorflow upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bdb2c3-198b-4c84-ac65-988a9a735749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source the setup Bash script to run specific configuration tasks\n",
    "! source ../setup.sh && setup_dataset && install_requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191b324-1a31-4b3a-a481-349730db73e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages and frameworks\n",
    "\n",
    "# uncomment below if using a notebook with a sagemaker notebook instance lifecycle config\n",
    "#! pip install -U pip --quiet\n",
    "#! pip install -r ../requirements.txt --quiet\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# debugging code \"Cleanup Called...\" gets displayed if get_logger is not set\n",
    "# the below code suppresses the \"Cleanup Called...\" output\n",
    "tf.get_logger().setLevel('INFO')\n",
    "\n",
    "# expecting 2.11\n",
    "# if 2.7, than logging errors will show \"Cleanup called...\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad1efc-dd91-43ce-b0a4-a90ef8eacdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scratch directory is apart of the .gitignore to ensure it is not committed to git\n",
    "%env SCRATCH=../scratch\n",
    "! [ -e \"${SCRATCH}\" ] || mkdir -p \"${SCRATCH}\"\n",
    "\n",
    "scratch_path = os.environ.get('SCRATCH', './scratch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3d2f3-404e-4a87-91e9-177b7219cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p \"${SCRATCH}\"/{real,tune,train,tf_datasets,train_lr/{left,right}}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d6ac1ab-8500-479c-9698-749f30386ebb",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03d1facb-2360-4d42-9b1a-ab49d72b215d",
   "metadata": {},
   "source": [
    "## Decompress the data for training\n",
    "\n",
    "Let's check for an existing S3 Bucket for training data.\n",
    "If it's not in S3, we will try other options..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d812792-42f8-4d22-adfc-4aca1e0d9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for existing s3 bucket\n",
    "! echo S3_BUCKET_DATA=$(aws s3 ls 2>/dev/null | cut -c21- | grep sagemaker-fingerprint-data) > .env\n",
    "\n",
    "# kludge: loadenv from .env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# if exists, download the objects from s3\n",
    "! [ ! -z \"$S3_BUCKET_DATA\" ] && \\\n",
    "  aws s3 sync s3://${S3_BUCKET_DATA}/train/left $SCRATCH/train/left --quiet && \\\n",
    "  aws s3 sync s3://${S3_BUCKET_DATA}/train/right $SCRATCH/train/right --quiet && \\\n",
    "  aws s3 sync s3://${S3_BUCKET_DATA}/real $SCRATCH/real --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ff397-1bef-4afe-8d69-615bf4509ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kludge: download dataset from git\n",
    "! git clone https://github.com/redhat-na-ssa/demo-datasci-fingerprint-data.git ${SCRATCH}/.raw\n",
    "\n",
    "! [ ! -d \"${SCRATCH}\"/train/left ] && \\\n",
    "  tar -Jxf ${SCRATCH}/.raw/left.tar.xz -C \"${SCRATCH}\"/train/ && \\\n",
    "  tar -Jxf ${SCRATCH}/.raw/right.tar.xz -C \"${SCRATCH}\"/train/ && \\\n",
    "  tar -Jxf ${SCRATCH}/.raw/real.tar.xz -C \"${SCRATCH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92cede-8686-4066-884e-0da8c64e0905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
