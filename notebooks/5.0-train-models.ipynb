{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e25c87-8bf9-470f-9700-4e61f9c54722",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe62c47d-63f4-4228-88ac-0c8aab0a65cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/app-root/src/datasci-fingerprint/scratch/tf_record_dataset\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9367d6-8b25-4585-95a9-76c51549f145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 20:43:34.293851: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-19 20:43:34.410844: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-19 20:43:35.250780: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-19 20:43:35.250846: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-19 20:43:35.250856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.1\n"
     ]
    }
   ],
   "source": [
    "# Install packages and frameworks\n",
    "\n",
    "# uncomment below if using a notebook with a sagemaker notebook instance lifecycle config\n",
    "#! pip install -U pip --quiet\n",
    "#! pip install -r ../requirements.txt --quiet\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# debugging code \"Cleanup Called...\" gets displayed if get_logger is not set\n",
    "# the below code suppresses the \"Cleanup Called...\" output\n",
    "tf.get_logger().setLevel('INFO')\n",
    "\n",
    "# expecting 2.11\n",
    "# if 2.7, than logging errors will show \"Cleanup called...\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f15966-0e85-4ea6-b2c2-0583fd6b3e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SCRATCH=../scratch\n"
     ]
    }
   ],
   "source": [
    "# scratch directory is apart of the .gitignore to ensure it is not committed to git\n",
    "%env SCRATCH=../scratch\n",
    "! [ -e \"${SCRATCH}\" ] || mkdir -p \"${SCRATCH}\"\n",
    "\n",
    "scratch_path = os.environ.get('SCRATCH', './scratch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd518a0-a6ed-4d1f-ad2a-b0160cb9e4d4",
   "metadata": {},
   "source": [
    "# Define a training strategy\n",
    "tf.distribute.Strategy is a TensorFlow API to distribute training across multiple GPUs, multiple machines, or TPUs. Using this API, you can distribute your existing models and training code with minimal code changes.\n",
    "\n",
    "Easy to use and support multiple user segments, including researchers, machine learning engineers, etc.\n",
    "Provide good performance out of the box.\n",
    "Easy switching between strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8208fd2d-f2fe-4d83-9b34-b68c677c1fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 20:43:40.071722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-19 20:43:40.105130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-19 20:43:40.107008: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display physical devices\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d5f5be0-1e60-463f-a992-a68371bd6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  example, single device\n",
    "#device=\"/cpu:0\"\n",
    "\n",
    "#  example, multiple devices devices\n",
    "device = '/device:GPU:0'\n",
    "\n",
    "#device = ['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff988be8-b63d-4b0c-ab35-c899eefc63cb",
   "metadata": {},
   "source": [
    "## One Device Strategy\n",
    "\n",
    "A distribution strategy for running on a single device. Device string identifier for the device on which the variables should be placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d3373b-62e1-4a16-987c-a766ac584c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 20:46:33.825756: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-19 20:46:33.828146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-19 20:46:33.830021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-19 20:46:33.831649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-19 20:46:34.594078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-19 20:46:34.596096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-19 20:46:34.597736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-19 20:46:34.599317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 546 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# uncomment to create a OneDeviceStrategy AND comment out the other strategy cells\n",
    "\n",
    "strategy = tf.distribute.OneDeviceStrategy(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d147056-d277-42f6-a0a5-30d5a4c2eb29",
   "metadata": {},
   "source": [
    "## Mirrored Strategy\n",
    "Supports synchronous distributed training on multiple GPUs on one machine. It creates one replica per GPU device. Each variable in the model is mirrored across all the replicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3653da0a-e679-4878-9d1e-c22eec82e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to create a MirroredStrategy\n",
    "\n",
    "#strategy = tf.distribute.MirroredStrategy(devices=device)\n",
    "#strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9ce8d-db5b-4f22-8966-cb5682dafdb0",
   "metadata": {},
   "source": [
    "### Multi-Worker Mirrored Strategy\n",
    "\n",
    "Multi-Worker MirroredStrategy is very similar to MirroredStrategy. It implements synchronous distributed training across multiple workers, each with potentially multiple GPUs. Similar to tf.distribute.MirroredStrategy, it creates copies of all variables in the model on each device across all workers.\n",
    "\n",
    "MultiWorkerMirroredStrategy has two implementations for cross-device communications. \n",
    "1. CommunicationImplementation.RING is RPC-based and supports both CPUs and GPUs. \n",
    "1. CommunicationImplementation.NCCL uses NCCL and provides state-of-art performance on GPUs but it doesn't support CPUs. \n",
    "1. CollectiveCommunication.AUTO defers the choice to Tensorflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3ecc573-abc7-44a8-9cfc-f3397837e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to create a Multi-worker Mirrored Strategy\n",
    "\n",
    "#communication_options = tf.distribute.experimental.CommunicationOptions(\n",
    "    # RING is RPC-based and supports both CPUs and GPUs.\n",
    "    #implementation=tf.distribute.experimental.CommunicationImplementation.RING)\n",
    "\n",
    "    # NCCL uses NCCL and provides state-of-art performance on GPUs but it doesn't support CPUs\n",
    "    #implementation=tf.distribute.experimental.CommunicationImplementation.NCCL)\n",
    "    \n",
    "    # AUTO defers the choice to Tensorflow.\n",
    "    #implementation=tf.distribute.experimental.CommunicationImplementation.AUTO)\n",
    "\n",
    "#strategy = tf.distribute.MultiWorkerMirroredStrategy(communication_options=communication_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e848481-9409-48f1-9006-b74430c15c05",
   "metadata": {},
   "source": [
    "# Load the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "046c8749-a03b-4ba4-9077-94e960c1b52e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "../scratch/tf_record_dataset/train/dataset_spec.pb/dataset_spec.pb; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m input_directory \u001b[38;5;241m=\u001b[39m scratch_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tf_record_dataset/train/dataset_spec.pb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:1927\u001b[0m, in \u001b[0;36mDatasetV2.load\u001b[0;34m(path, element_spec, compression, reader_func)\u001b[0m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;66;03m# dataset_ops->load_ops->dataset_ops\u001b[39;00m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m-> 1927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m    \u001b[49m\u001b[43melement_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreader_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreader_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/tensorflow/python/data/ops/load_op.py:36\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, element_spec, compression, reader_func)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(path,\n\u001b[1;32m     33\u001b[0m          element_spec,\n\u001b[1;32m     34\u001b[0m          compression,\n\u001b[1;32m     35\u001b[0m          reader_func):\n\u001b[0;32m---> 36\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_LoadDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreader_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/tensorflow/python/data/ops/load_op.py:57\u001b[0m, in \u001b[0;36m_LoadDataset.__init__\u001b[0;34m(self, path, element_spec, compression, reader_func)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     54\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn graph mode the `element_spec` argument must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gfile\u001b[38;5;241m.\u001b[39mGFile(\n\u001b[1;32m     56\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, dataset_ops\u001b[38;5;241m.\u001b[39mDATASET_SPEC_FILENAME), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 57\u001b[0m   encoded_spec \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m struct_pb \u001b[38;5;241m=\u001b[39m nested_structure_coder\u001b[38;5;241m.\u001b[39mstruct_pb2\u001b[38;5;241m.\u001b[39mStructuredValue()\n\u001b[1;32m     59\u001b[0m struct_pb\u001b[38;5;241m.\u001b[39mParseFromString(encoded_spec)\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/tensorflow/python/lib/io/file_io.py:116\u001b[0m, in \u001b[0;36mFileIO.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the contents of a file as a string.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m  Starts reading from current position in file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    string if in string (regular) mode.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preread_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    118\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/tensorflow/python/lib/io/file_io.py:77\u001b[0m, in \u001b[0;36mFileIO._preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_check_passed:\n\u001b[1;32m     75\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mPermissionDeniedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     76\u001b[0m                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt open for reading\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_buf \u001b[38;5;241m=\u001b[39m \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBufferedInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ../scratch/tf_record_dataset/train/dataset_spec.pb/dataset_spec.pb; No such file or directory"
     ]
    }
   ],
   "source": [
    "input_directory = scratch_path + '/tf_record_dataset/train/dataset_spec.pb'\n",
    "\n",
    "tf.data.Dataset.load(input_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d766260-d590-4582-88aa-7f7e49322146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
