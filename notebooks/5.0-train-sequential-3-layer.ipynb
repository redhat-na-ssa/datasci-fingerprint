{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb86f8e1-b38b-4d0c-92b5-257c657ce304",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0685747-4565-4cf5-ae05-ed5d7ea051da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 04:30:35.822774: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 04:30:35.939462: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-25 04:30:36.871377: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-25 04:30:36.871448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-25 04:30:36.871458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.1\n"
     ]
    }
   ],
   "source": [
    "# Install packages and frameworks\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# expecting 2.11\n",
    "# if 2.7, than logging errors will show \"Cleanup called...\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba71e1f6-f29c-4c35-8a92-a60c8851fd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SCRATCH=../scratch\n"
     ]
    }
   ],
   "source": [
    "# scratch directory is apart of the .gitignore to ensure it is not committed to git\n",
    "%env SCRATCH=../scratch\n",
    "! [ -e \"${SCRATCH}\" ] || mkdir -p \"${SCRATCH}\"\n",
    "\n",
    "scratch_path = os.environ.get('SCRATCH', './scratch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edfc60d-2aec-4516-8cb7-8837441b8391",
   "metadata": {},
   "source": [
    "# Load the saved datasets\n",
    "\n",
    "The TFRecord format is a simple format for storing a sequence of binary records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165835a8-5f4b-4c1d-9dfa-461e290b9b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 04:30:38.716712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-25 04:30:38.743082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-25 04:30:38.744872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-25 04:30:38.747041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 04:30:38.749786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-25 04:30:38.751516: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-25 04:30:38.753174: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-25 04:30:39.525052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-25 04:30:39.527077: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-25 04:30:39.528830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-25 04:30:39.530494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 58 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = scratch_path + '/tf_datasets/train/'\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "\n",
    "train_ds = tf.data.Dataset.load(path)\n",
    "train_ds = train_ds.with_options(options)\n",
    "\n",
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "368c217f-f53f-4700-8fdc-19a14528a37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = scratch_path + '/tf_datasets/validate/'\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "\n",
    "validation_ds = tf.data.Dataset.load(path)\n",
    "validation_ds = validation_ds.with_options(options)\n",
    "\n",
    "validation_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f42449-1ee8-4a92-a2af-a8d484843a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = scratch_path + '/tf_datasets/test/'\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "\n",
    "test_ds = tf.data.Dataset.load(path)\n",
    "test_ds = test_ds.with_options(options)\n",
    "\n",
    "test_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b7454a-3458-4213-9265-dd25d88f1466",
   "metadata": {},
   "source": [
    "## Configure the datasets for performance\n",
    "\n",
    "Let's make sure to use buffered prefetching so we can yield data from disk without having I/O become blocking. These are two important methods you should use when loading data.\n",
    "\n",
    "1. `Caching` a dataset, either in memory or on local storage. This will save some operations (like file opening and data reading) from being executed during each epoch.\n",
    "1. `Prefetching` overlaps the preprocessing and model execution of a training step. While the model is executing training step s, the input pipeline is reading the data for step s+1. Doing so reduces the step time to the maximum (as opposed to the sum) of the training and the time it takes to extract the data.\n",
    "\n",
    "[Optimising your input pipeline performance with tf.data (part 1)](https://towardsdatascience.com/optimising-your-input-pipeline-performance-with-tf-data-part-1-32e52a30cac4)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4c160fc-7822-4cf5-8eb5-9c5c76ef8748",
   "metadata": {},
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da87c9-0c6b-49af-ae0e-c0f3b98515a0",
   "metadata": {},
   "source": [
    "# Check the device spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c352932-39d4-4ea2-adc8-c761506bf7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display physical devices\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4057ce7-788c-4e1c-a770-708d73c67ebc",
   "metadata": {},
   "source": [
    "# Set the training strategy based on your devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b89efe1-c3a1-4b80-a7ff-4d30c50fb310",
   "metadata": {},
   "source": [
    "## One Device\n",
    "\n",
    "Typical usage of this strategy could be testing your code with the tf.distribute.Strategy API before switching to other strategies which actually distribute to multiple devices/machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8ee4bcd-e215-414e-b73b-67c9bd65a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  example, single device\n",
    "#device=\"/cpu:0\"\n",
    "device=\"/GPU:0\"\n",
    "\n",
    "strategy = tf.distribute.OneDeviceStrategy(device=device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc5eed84-f581-4bdd-8770-3cb3d0b405ec",
   "metadata": {},
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "#  when keras run with gpu, it uses almost all vram. So we needed to give memory_limit for each notebook as shown below\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232d3709-db26-4a83-ac98-a36013a86e76",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443bfbbf-3f3f-45a2-9586-85bf8d04657d",
   "metadata": {},
   "source": [
    "## Set some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d699ebcd-4965-416a-93a6-654e49fd0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for consistency\n",
    "img_height = 96              # desired height\n",
    "img_width = 96               # desired width\n",
    "batch_size = 32              # batch inputs in 32\n",
    "seed_train_validation = 42   # Must be same for train_ds and val_ds\n",
    "validation_split = 0.3       # move 30% of the data into validation\n",
    "class_names = ['left', 'right']\n",
    "\n",
    "dataFormat=\"channels_last\"\n",
    "num_classes = len(class_names)\n",
    "inputShape=(img_height, img_width, 1)\n",
    "chanDim = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32f43e-eb02-4411-b593-99e860cdd4e0",
   "metadata": {},
   "source": [
    "tf.keras models are optimized to make predictions on a batch, or collection, of examples at once. Accordingly, even though you're using a single image, you need to add it to a list:\n",
    "\n",
    "## Setup the layers\n",
    "\n",
    "The Sequential model consists of three convolution blocks (tf.keras.layers.Conv2D) with a max pooling layer (tf.keras.layers.MaxPooling2D) in each of them. There's a fully-connected layer (tf.keras.layers.Dense) with 128 units on top of it that is activated by a ReLU activation function ('relu'). This model has not been tuned in any way—the goal is to show you the mechanics using the datasets you just created. To learn more about image classification, visit the Image classification tutorial.\n",
    "\n",
    "Here's an example of Python code using Keras to create a sequential classification model that accepts 96x96x1 input images.\n",
    "\n",
    "In this example, we start with three convolutional layers, each followed by a max pooling layer to downsample the input. Then, we flatten the output from the convolutional layers and add two fully connected layers. Finally, we add an output layer with the number of classes and compile the model using an optimizer (e.g., Adam) and a loss function (e.g., categorical cross-entropy).\n",
    "\n",
    "Make sure to replace num_classes with the actual number of classes in your classification problem.\n",
    "```\n",
    "import tensorflow as tf    \n",
    "\n",
    "model = tf.keras.Model(...)\n",
    "\n",
    "# Run training on GPU\n",
    "with tf.device('/gpu:0'):\n",
    "    model.fit(...)\n",
    "\n",
    "# Run inference on CPU\n",
    "with tf.device('/cpu:0'):\n",
    "    model.predict(...)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122651a9-8379-408c-9bae-1d018f0b496d",
   "metadata": {},
   "source": [
    "# Set up the layers\n",
    "The basic building block of a neural network is the layer. Layers extract representations from the data fed into them. Hopefully, these representations are meaningful for the problem at hand.\n",
    "\n",
    "Most of deep learning consists of chaining together simple layers. Most layers, such as tf.keras.layers.Dense, have parameters that are learned during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6f6b0d3-6ade-4496-b898-4553258b2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from keras.utils import plot_model\n",
    "\n",
    "with strategy.scope():\n",
    "    fp_3_layer_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=inputShape),\n",
    "        tf.keras.layers.Reshape(target_shape=inputShape),\n",
    "\n",
    "        # layer 1\n",
    "        tf.keras.layers.Conv2D(96, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # layer 2\n",
    "        tf.keras.layers.Conv2D(96, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # layer 3\n",
    "        tf.keras.layers.Conv2D(96, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes),\n",
    "        tf.keras.layers.Softmax()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5efe82d8-dbc0-46fd-8062-69dd35a4c432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# Visualize the model\n",
    "plot_model(fp_3_layer_model, to_file='fp_3_layer_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc19a77c-2cee-49e4-9da7-3841f2b320ec",
   "metadata": {},
   "source": [
    "# Compile the model\n",
    "\n",
    "Before the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n",
    "\n",
    "Loss function —This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n",
    "Optimizer —This is how the model is updated based on the data it sees and its loss function.\n",
    "Metrics —Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0547dca-a170-49e6-a1fe-198a5da84176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_1 (Reshape)         (None, 96, 96, 1)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 94, 94, 96)        960       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 47, 47, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 45, 45, 96)        83040     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 22, 22, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 20, 20, 96)        83040     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 10, 10, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 9600)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               2457856   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,625,410\n",
      "Trainable params: 2,625,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fp_3_layer_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(\n",
    "                  from_logits=False,\n",
    "                  label_smoothing=0.0,\n",
    "                  axis=-1,\n",
    "                  #reduction=losses_utils.ReductionV2.AUTO,\n",
    "                  name='categorical_crossentropy'),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "fp_3_layer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ee8cf-58e1-46aa-95ba-82d89736d9ea",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Training the neural network model requires the following steps:\n",
    "\n",
    "Feed the training data to the model. In this example, the training data is in the train_images and train_labels arrays.\n",
    "The model learns to associate images and labels.\n",
    "You ask the model to make predictions about a test set—in this example, the test_images array.\n",
    "Verify that the predictions match the labels from the test_labels array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f24a68a-4ac5-47fe-a429-4852569d80b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 04:32:53.582160: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 103.55MiB (rounded to 108576768)requested by op sequential_1/conv2d_5/Relu\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-05-25 04:32:53.582203: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2023-05-25 04:32:53.582217: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 45, Chunks in use: 45. 11.2KiB allocated for chunks. 11.2KiB in use in bin. 1.5KiB client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582228: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 24, Chunks in use: 24. 12.0KiB allocated for chunks. 12.0KiB in use in bin. 9.0KiB client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582236: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 7, Chunks in use: 7. 7.2KiB allocated for chunks. 7.2KiB in use in bin. 7.0KiB client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582245: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 12, Chunks in use: 12. 33.0KiB allocated for chunks. 33.0KiB in use in bin. 32.2KiB client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582254: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582267: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582275: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582282: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582291: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 2, Chunks in use: 2. 192.0KiB allocated for chunks. 192.0KiB in use in bin. 192.0KiB client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582300: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 178.2KiB allocated for chunks. 178.2KiB in use in bin. 96.0KiB client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582308: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 17, Chunks in use: 17. 5.58MiB allocated for chunks. 5.58MiB in use in bin. 5.38MiB client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582316: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 641.5KiB allocated for chunks. 641.5KiB in use in bin. 324.0KiB client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582324: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 4, Chunks in use: 4. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582332: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582339: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582347: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 3, Chunks in use: 2. 29.45MiB allocated for chunks. 18.75MiB in use in bin. 18.75MiB client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582356: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 1. 17.80MiB allocated for chunks. 17.80MiB in use in bin. 9.38MiB client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582366: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582374: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582381: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582389: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-25 04:32:53.582397: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 103.55MiB was 64.00MiB, Chunk State: \n",
      "2023-05-25 04:32:53.582412: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 61210624\n",
      "2023-05-25 04:32:53.582424: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44000000 of size 1280 next 1\n",
      "2023-05-25 04:32:53.582431: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44000500 of size 256 next 2\n",
      "2023-05-25 04:32:53.582438: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44000600 of size 256 next 3\n",
      "2023-05-25 04:32:53.582445: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44000700 of size 256 next 4\n",
      "2023-05-25 04:32:53.582451: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44000800 of size 256 next 6\n",
      "2023-05-25 04:32:53.582458: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44000900 of size 512 next 7\n",
      "2023-05-25 04:32:53.582466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44000b00 of size 256 next 5\n",
      "2023-05-25 04:32:53.582472: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44000c00 of size 256 next 8\n",
      "2023-05-25 04:32:53.582479: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44000d00 of size 512 next 13\n",
      "2023-05-25 04:32:53.582485: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44000f00 of size 512 next 16\n",
      "2023-05-25 04:32:53.582492: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44001100 of size 512 next 18\n",
      "2023-05-25 04:32:53.582499: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44001300 of size 512 next 20\n",
      "2023-05-25 04:32:53.582505: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44001500 of size 256 next 11\n",
      "2023-05-25 04:32:53.582512: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44001600 of size 256 next 12\n",
      "2023-05-25 04:32:53.582519: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44001700 of size 1024 next 24\n",
      "2023-05-25 04:32:53.582525: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44001b00 of size 256 next 22\n",
      "2023-05-25 04:32:53.582532: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44001c00 of size 256 next 23\n",
      "2023-05-25 04:32:53.582538: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44001d00 of size 512 next 39\n",
      "2023-05-25 04:32:53.582545: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44001f00 of size 512 next 40\n",
      "2023-05-25 04:32:53.582552: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44002100 of size 512 next 42\n",
      "2023-05-25 04:32:53.582558: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44002300 of size 512 next 43\n",
      "2023-05-25 04:32:53.582565: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44002500 of size 512 next 9\n",
      "2023-05-25 04:32:53.582571: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44002700 of size 3584 next 10\n",
      "2023-05-25 04:32:53.582578: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44003500 of size 256 next 28\n",
      "2023-05-25 04:32:53.582585: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44003600 of size 256 next 27\n",
      "2023-05-25 04:32:53.582591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44003700 of size 256 next 29\n",
      "2023-05-25 04:32:53.582598: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44003800 of size 256 next 32\n",
      "2023-05-25 04:32:53.582604: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44003900 of size 256 next 33\n",
      "2023-05-25 04:32:53.582611: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44003a00 of size 256 next 34\n",
      "2023-05-25 04:32:53.582617: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44003b00 of size 256 next 35\n",
      "2023-05-25 04:32:53.582624: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44003c00 of size 256 next 36\n",
      "2023-05-25 04:32:53.582630: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44003d00 of size 256 next 30\n",
      "2023-05-25 04:32:53.582637: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44003e00 of size 2048 next 31\n",
      "2023-05-25 04:32:53.582644: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44004600 of size 3584 next 37\n",
      "2023-05-25 04:32:53.582652: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44005400 of size 3584 next 38\n",
      "2023-05-25 04:32:53.582659: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44006200 of size 512 next 46\n",
      "2023-05-25 04:32:53.582665: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44006400 of size 512 next 49\n",
      "2023-05-25 04:32:53.582672: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44006600 of size 512 next 50\n",
      "2023-05-25 04:32:53.582679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44006800 of size 512 next 53\n",
      "2023-05-25 04:32:53.582688: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44006a00 of size 512 next 54\n",
      "2023-05-25 04:32:53.582695: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44006c00 of size 182528 next 26\n",
      "2023-05-25 04:32:53.582702: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44033500 of size 98304 next 25\n",
      "2023-05-25 04:32:53.582709: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4404b500 of size 368640 next 15\n",
      "2023-05-25 04:32:53.582719: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e440a5500 of size 331776 next 14\n",
      "2023-05-25 04:32:53.582725: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e440f6500 of size 331776 next 17\n",
      "2023-05-25 04:32:53.582732: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44147500 of size 331776 next 19\n",
      "2023-05-25 04:32:53.582739: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44198500 of size 331776 next 21\n",
      "2023-05-25 04:32:53.582746: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e441e9500 of size 331776 next 41\n",
      "2023-05-25 04:32:53.582754: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4423a500 of size 331776 next 44\n",
      "2023-05-25 04:32:53.582761: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4428b500 of size 331776 next 45\n",
      "2023-05-25 04:32:53.582768: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e442dc500 of size 331776 next 47\n",
      "2023-05-25 04:32:53.582776: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4432d500 of size 331776 next 48\n",
      "2023-05-25 04:32:53.582783: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4437e500 of size 331776 next 51\n",
      "2023-05-25 04:32:53.582790: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e443cf500 of size 331776 next 52\n",
      "2023-05-25 04:32:53.582797: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44420500 of size 98304 next 55\n",
      "2023-05-25 04:32:53.582805: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44438500 of size 1024 next 56\n",
      "2023-05-25 04:32:53.582814: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44438900 of size 1024 next 57\n",
      "2023-05-25 04:32:53.582821: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44438d00 of size 2048 next 58\n",
      "2023-05-25 04:32:53.582827: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44439500 of size 2048 next 59\n",
      "2023-05-25 04:32:53.582834: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44439d00 of size 256 next 60\n",
      "2023-05-25 04:32:53.582841: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44439e00 of size 256 next 61\n",
      "2023-05-25 04:32:53.582849: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e44439f00 of size 256 next 62\n",
      "2023-05-25 04:32:53.582856: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443a000 of size 256 next 63\n",
      "2023-05-25 04:32:53.582863: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443a100 of size 256 next 64\n",
      "2023-05-25 04:32:53.582871: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443a200 of size 512 next 65\n",
      "2023-05-25 04:32:53.582878: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443a400 of size 512 next 71\n",
      "2023-05-25 04:32:53.582884: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443a600 of size 512 next 74\n",
      "2023-05-25 04:32:53.582891: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443a800 of size 256 next 66\n",
      "2023-05-25 04:32:53.582898: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443a900 of size 1024 next 79\n",
      "2023-05-25 04:32:53.582906: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443ad00 of size 256 next 78\n",
      "2023-05-25 04:32:53.582913: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443ae00 of size 256 next 82\n",
      "2023-05-25 04:32:53.582919: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443af00 of size 256 next 77\n",
      "2023-05-25 04:32:53.582928: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443b000 of size 256 next 83\n",
      "2023-05-25 04:32:53.582935: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443b100 of size 256 next 85\n",
      "2023-05-25 04:32:53.582942: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443b200 of size 3584 next 72\n",
      "2023-05-25 04:32:53.582948: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443c000 of size 3584 next 73\n",
      "2023-05-25 04:32:53.582968: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443ce00 of size 2048 next 84\n",
      "2023-05-25 04:32:53.582977: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443d600 of size 3584 next 86\n",
      "2023-05-25 04:32:53.582984: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443e400 of size 512 next 87\n",
      "2023-05-25 04:32:53.582991: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443e600 of size 512 next 88\n",
      "2023-05-25 04:32:53.583000: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4443e800 of size 656896 next 75\n",
      "2023-05-25 04:32:53.583007: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e444dee00 of size 505344 next 67\n",
      "2023-05-25 04:32:53.583015: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4455a400 of size 256 next 68\n",
      "2023-05-25 04:32:53.583022: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4455a500 of size 256 next 69\n",
      "2023-05-25 04:32:53.583031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4455a600 of size 1179648 next 70\n",
      "2023-05-25 04:32:53.583038: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4467a600 of size 331776 next 76\n",
      "2023-05-25 04:32:53.583046: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e446cb600 of size 331776 next 89\n",
      "2023-05-25 04:32:53.583055: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4471c600 of size 512 next 90\n",
      "2023-05-25 04:32:53.583064: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4471c800 of size 512 next 91\n",
      "2023-05-25 04:32:53.583074: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4471ca00 of size 331776 next 92\n",
      "2023-05-25 04:32:53.583080: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4476da00 of size 331776 next 93\n",
      "2023-05-25 04:32:53.583087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e447bea00 of size 512 next 94\n",
      "2023-05-25 04:32:53.583096: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e447bec00 of size 512 next 95\n",
      "2023-05-25 04:32:53.583105: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e447bee00 of size 18663424 next 81\n",
      "2023-05-25 04:32:53.583114: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e4598b600 of size 9830400 next 80\n",
      "2023-05-25 04:32:53.583123: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e462eb600 of size 9830400 next 96\n",
      "2023-05-25 04:32:53.583130: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4b600 of size 1024 next 97\n",
      "2023-05-25 04:32:53.583137: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4ba00 of size 1024 next 98\n",
      "2023-05-25 04:32:53.583145: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4be00 of size 2048 next 99\n",
      "2023-05-25 04:32:53.583152: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4c600 of size 2048 next 100\n",
      "2023-05-25 04:32:53.583159: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4ce00 of size 256 next 101\n",
      "2023-05-25 04:32:53.583168: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4cf00 of size 256 next 102\n",
      "2023-05-25 04:32:53.583174: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4d000 of size 256 next 103\n",
      "2023-05-25 04:32:53.583183: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4d100 of size 256 next 104\n",
      "2023-05-25 04:32:53.583189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4d200 of size 256 next 105\n",
      "2023-05-25 04:32:53.583196: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4d300 of size 256 next 106\n",
      "2023-05-25 04:32:53.583203: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4d400 of size 256 next 107\n",
      "2023-05-25 04:32:53.583211: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4d500 of size 256 next 108\n",
      "2023-05-25 04:32:53.583218: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46c4d600 of size 1179648 next 109\n",
      "2023-05-25 04:32:53.583227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46d6d600 of size 256 next 110\n",
      "2023-05-25 04:32:53.583235: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46d6d700 of size 256 next 111\n",
      "2023-05-25 04:32:53.583244: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46d6d800 of size 1179648 next 112\n",
      "2023-05-25 04:32:53.583253: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46e8d800 of size 256 next 113\n",
      "2023-05-25 04:32:53.583262: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46e8d900 of size 256 next 114\n",
      "2023-05-25 04:32:53.583268: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46e8da00 of size 256 next 115\n",
      "2023-05-25 04:32:53.583277: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f2e46e8db00 of size 1179648 next 116\n",
      "2023-05-25 04:32:53.583286: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f2e46fadb00 of size 11216128 next 18446744073709551615\n",
      "2023-05-25 04:32:53.583295: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2023-05-25 04:32:53.583304: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 45 Chunks of size 256 totalling 11.2KiB\n",
      "2023-05-25 04:32:53.583313: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 24 Chunks of size 512 totalling 12.0KiB\n",
      "2023-05-25 04:32:53.583322: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 1024 totalling 6.0KiB\n",
      "2023-05-25 04:32:53.583331: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-05-25 04:32:53.583338: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 2048 totalling 12.0KiB\n",
      "2023-05-25 04:32:53.583347: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 3584 totalling 21.0KiB\n",
      "2023-05-25 04:32:53.583355: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 98304 totalling 192.0KiB\n",
      "2023-05-25 04:32:53.583363: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 182528 totalling 178.2KiB\n",
      "2023-05-25 04:32:53.583371: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 15 Chunks of size 331776 totalling 4.75MiB\n",
      "2023-05-25 04:32:53.583381: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 368640 totalling 360.0KiB\n",
      "2023-05-25 04:32:53.583391: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 505344 totalling 493.5KiB\n",
      "2023-05-25 04:32:53.583400: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 656896 totalling 641.5KiB\n",
      "2023-05-25 04:32:53.583407: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 1179648 totalling 4.50MiB\n",
      "2023-05-25 04:32:53.583415: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 9830400 totalling 18.75MiB\n",
      "2023-05-25 04:32:53.583424: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 18663424 totalling 17.80MiB\n",
      "2023-05-25 04:32:53.583431: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 47.68MiB\n",
      "2023-05-25 04:32:53.583440: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 61210624 memory_limit_: 61210624 available bytes: 0 curr_region_allocation_bytes_: 122421248\n",
      "2023-05-25 04:32:53.583452: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                        61210624\n",
      "InUse:                        49994496\n",
      "MaxInUse:                     49994496\n",
      "NumAllocs:                         202\n",
      "MaxAllocSize:                 18663424\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-05-25 04:32:53.583468: W tensorflow/tsl/framework/bfc_allocator.cc:492] ******************************xxxxxxxxxxxxx***************************************__________________\n",
      "2023-05-25 04:32:53.583494: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops_fused_impl.h:766 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,96,94,94] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_1/conv2d_5/Relu' defined at (most recent call last):\n    File \"/usr/lib64/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib64/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/app-root/lib64/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/opt/app-root/lib64/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib64/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib64/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib64/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_25437/2960897162.py\", line 2, in <module>\n      fp_3_layer_model.fit(train_ds, epochs=10, validation_data=validation_ds)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/backend.py\", line 5369, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_1/conv2d_5/Relu'\nOOM when allocating tensor with shape[32,96,94,94] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_1/conv2d_5/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3222]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mfp_3_layer_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/app-root/lib64/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_1/conv2d_5/Relu' defined at (most recent call last):\n    File \"/usr/lib64/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib64/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/app-root/lib64/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/opt/app-root/lib64/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib64/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib64/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib64/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/app-root/lib64/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/app-root/lib64/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_25437/2960897162.py\", line 2, in <module>\n      fp_3_layer_model.fit(train_ds, epochs=10, validation_data=validation_ds)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/activations.py\", line 317, in relu\n      return backend.relu(\n    File \"/opt/app-root/lib64/python3.9/site-packages/keras/backend.py\", line 5369, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_1/conv2d_5/Relu'\nOOM when allocating tensor with shape[32,96,94,94] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_1/conv2d_5/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3222]"
     ]
    }
   ],
   "source": [
    "with tf.device(device):\n",
    "    fp_3_layer_model.fit(train_ds, epochs=10, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6b0f0-9baf-4611-be69-3d63c41cb83c",
   "metadata": {},
   "source": [
    "# Evaluate accuracy\n",
    "\n",
    "Next, compare how the model performs on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f34ff61-92d4-4f93-9df6-a9750100b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = fp_3_layer_model.evaluate(test_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46843f6-1787-4a36-9d08-fbbec3e39d0c",
   "metadata": {},
   "source": [
    "# Print Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fdc063-7afd-4b79-bfdf-6f9ec5480104",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTest accuracy:', test_acc)\n",
    "print('\\nTest loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1ab9f-9abc-4770-993e-ade624368f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
