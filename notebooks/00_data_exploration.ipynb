{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef556e5-682f-4338-86d0-e423cb58e27c",
   "metadata": {},
   "source": [
    "# Part I: Data Exloration\n",
    "\n",
    "Any good data science problem will start with understanding the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4151a4-30f5-4492-b5b2-6c43239b5019",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "A common tasks in any notebook for data analysis to model experimentation includes setup. These following cells will:\n",
    "1. create a virtual isolated environment, so we can work on different projects without having conflicting library versions\n",
    "1. sets up a scratch folder to load the training data into\n",
    "1. installs the requirements.txt software and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa61d3-7e9b-4279-ae60-bdb52aaca1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cd .. && ./scripts/bootstrap.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827d3ea-44e2-4140-b4fc-f772cf7aaf9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -u pip -q\n",
    "! pip install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b58ee8-b7fe-440e-b030-4c3b0c263992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1f3d5-bb9f-4ac7-8c53-100d63135afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scratch directory is apart of the .gitignore to ensure it is not committed to git\n",
    "%env SCRATCH=../scratch\n",
    "! [ -e \"${SCRATCH}\" ] || mkdir -p \"${SCRATCH}\"\n",
    "\n",
    "scratch_path = os.environ.get('SCRATCH', './scratch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e73f3d-ccad-4165-9e74-bccd2be2ea75",
   "metadata": {},
   "source": [
    "# Examine and understand data\n",
    "\n",
    "We will be labeling data using the `tf.keras.utils.image_dataset_from_directory` utility, which will infer the label for the subsequent images from the parent folder name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be2303-e120-4ca8-9590-c457105a28f1",
   "metadata": {},
   "source": [
    "## Count the subdirectories\n",
    "\n",
    "Let's analyze how many subfolders of images we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd525ff1-bcc5-46b5-8cb0-d86ff123d478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_folder = scratch_path + '/train'\n",
    "subdirectories = [f.path for f in os.scandir(path_to_folder) if f.is_dir()]\n",
    "\n",
    "# print the number of subdirectories\n",
    "print(len(subdirectories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a5c62-7054-407f-836c-317f8c0c37e0",
   "metadata": {},
   "source": [
    "## Count the total images\n",
    "\n",
    "Counting the total number of images combined in each directory will indicate if we have enough data to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b581ed-a0dc-4e4c-808b-083e83385db4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_count = len(list(glob.glob(scratch_path +'/train/*/*')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e087ed7-16d8-4e2e-a54e-5c58cb9de0d1",
   "metadata": {},
   "source": [
    "## List the subdirectories\n",
    "\n",
    "Let's list the subdirectories to understand what labels we will be predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a872e-2886-48ac-a1c0-1005148b666d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a list of all files and directories in the path\n",
    "path_to_images = scratch_path + '/train'\n",
    "\n",
    "contents = os.listdir(path_to_images)\n",
    "\n",
    "# Loop through each item in the list\n",
    "for item in contents:\n",
    "    # Check if the item is a directory\n",
    "    if os.path.isdir(os.path.join(path_to_images, item)):\n",
    "        print(\"Found directory:\", item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b51b3c-f4e7-4778-a2bc-04ab7a785ee5",
   "metadata": {},
   "source": [
    "## Count images in subdirectories\n",
    "\n",
    "Let's see if we have an even distribution of images in each subdirectory or if we have bias/skewed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fede7ef-9eb9-4c07-9761-1f280d3d3717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_path = scratch_path + '/train'\n",
    "num_images = 0\n",
    "\n",
    "# Iterate over each subdirectory\n",
    "for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "    # Count the number of image files in the current subdirectory\n",
    "    for filename in filenames:\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            num_images += 1\n",
    "\n",
    "    # Print the number of image files in the current subdirectory\n",
    "    print(f\"Found {num_images} images in directory: {dirpath}\")\n",
    "    num_images = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3fdc4b-26fa-4be4-a736-1336323b4700",
   "metadata": {},
   "source": [
    "## Visualize the distribution of images\n",
    "\n",
    "We can visually represent the images in each class with a bar chart to easily identify imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d6730b-840b-4652-9e34-36c0fee81727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subdirectories = [os.path.join(root_path, d) for d in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, d))]\n",
    "\n",
    "# Count the number of images in each subdirectory\n",
    "counts = [0] * len(subdirectories)\n",
    "for i, directory in enumerate(subdirectories):\n",
    "    counts[i] = len(os.listdir(directory))\n",
    "\n",
    "# Create a bar chart to visualize the distribution\n",
    "plt.bar(subdirectories, counts)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41202121-02b6-4566-9922-a758484fc2d9",
   "metadata": {},
   "source": [
    "You are looking for imbalances in the dataset that would result in bias in the model and what it predicts on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438a027-cb2e-4f93-99a7-b343a9bda48d",
   "metadata": {},
   "source": [
    "## Analyzing Image Properties\n",
    "\n",
    "Now we can examine the image properties to identify what transformations we might need to account for before passing to a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3d595-1e4a-4f0d-b6dd-5935b09bddce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize empty lists to store the information\n",
    "sizes = []\n",
    "resolutions = []\n",
    "color_distributions = []\n",
    "\n",
    "# Iterate over each image file in each subdirectory\n",
    "for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "    for filename in filenames:\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Load the image file using OpenCV\n",
    "            img_path = os.path.join(dirpath, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            # Extract the size of the image\n",
    "            size = os.path.getsize(img_path)\n",
    "            sizes.append(size)\n",
    "\n",
    "            # Extract the resolution of the image\n",
    "            resolution = img.shape[:2]\n",
    "            resolutions.append(resolution)\n",
    "\n",
    "            # Extract the color distribution of the image\n",
    "            color_distribution = np.bincount(img.flatten(), minlength=256)\n",
    "            color_distributions.append(color_distribution)\n",
    "\n",
    "# Convert the lists to numpy arrays for easier manipulation\n",
    "sizes = np.array(sizes)\n",
    "resolutions = np.array(resolutions)\n",
    "color_distributions = np.array(color_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b313d-b543-43b7-bcea-bd86b14cf574",
   "metadata": {},
   "source": [
    "### Histogram of image sizes\n",
    "\n",
    "We can visualize the range of different image sizes in our dataset to understand how best to resize the images.\n",
    "\n",
    "We will use Plotly to enrich the visualization experience by providing an interactive chart to zoom and uncover additional insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a23ccf-e507-4552-993c-96741d425fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Root directory path\n",
    "root_path = scratch_path + '/train'\n",
    "\n",
    "# List to store file sizes\n",
    "sizes = []\n",
    "\n",
    "# Iterate over each file in the root directory and its subdirectories\n",
    "for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "    for filename in filenames:\n",
    "        # Get the full path of the file\n",
    "        file_path = os.path.join(dirpath, filename)\n",
    "        # Get the file size in bytes\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        # Convert file size to MB and add to the list\n",
    "        sizes.append(file_size / 1_000_000)\n",
    "\n",
    "# Create a histogram figure with plotly\n",
    "fig = px.histogram(x=sizes, nbins=50, title=\"Distribution of Image Sizes\")\n",
    "\n",
    "# Customize the plot\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"File Size (MB)\",\n",
    "    yaxis_title=\"Number of Images\",\n",
    "    showlegend=False,\n",
    "    bargap=0.1,\n",
    "    bargroupgap=0.1\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232fed5-bcca-4b49-a48a-03350c1eb8f5",
   "metadata": {},
   "source": [
    "### Scatterplot of image resolutions\n",
    "\n",
    "Understanding the width and height, or resolution, of an image may reveal irregularities to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53b403-e309-483a-aaa1-9d36ca71957a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot figure with plotly\n",
    "fig = px.scatter(x=resolutions[:, 0], y=resolutions[:, 1], title=\"Distribution of Image Resolutions\")\n",
    "\n",
    "# Customize the plot\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Width (pixels)\",\n",
    "    yaxis_title=\"Height (pixels)\",\n",
    "    showlegend=False,\n",
    "    hovermode=\"closest\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(l=50, r=50, b=50, t=50, pad=4)\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f958c6-8a1f-46a4-b088-325efc2c3e4d",
   "metadata": {},
   "source": [
    "## 3D scatterplot of image resolutions\n",
    "\n",
    "It's overkill, but demonstrates the power of visualization if we had more variability in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa5d5a-98c2-487d-b0bb-b5e7e1b9e028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with the resolutions\n",
    "df = pd.DataFrame(resolutions, columns=['width', 'height'])\n",
    "\n",
    "# Create a 3D scatter plot with plotly\n",
    "fig = px.scatter_3d(df, x='width', y='height', z=df.index,\n",
    "                    title='Distribution of Image Resolutions',\n",
    "                    labels={'width': 'Width (pixels)',\n",
    "                            'height': 'Height (pixels)',\n",
    "                            'index': 'Image Index'},\n",
    "                    color=df.index)\n",
    "\n",
    "# Customize the plot\n",
    "fig.update_traces(marker=dict(size=2, line=dict(width=0.5)))\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b8e2d-d142-4047-a7c4-bcc1c429ce1f",
   "metadata": {},
   "source": [
    "You will observe we have two sizes of images ~(300x240) and ~(103x96). This means we will need to do some preprocessing transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aaa3eb-08fc-45bc-bb5c-c819a2c386f5",
   "metadata": {},
   "source": [
    "## Plot the mean color distribution\n",
    "\n",
    "Sometime the distribution of color can provide trends and patterns that are useful to normalizing and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4929f188-4859-43e0-963d-6776503e5fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the mean color distribution across all images\n",
    "mean_color_distribution = np.mean(color_distributions, axis=0)\n",
    "\n",
    "# Create a bar chart of the mean color distribution\n",
    "fig = go.Figure(\n",
    "    go.Bar(x=np.arange(256), y=mean_color_distribution, name=\"Mean Color Distribution\")\n",
    ")\n",
    "\n",
    "# Set the title and axis labels\n",
    "fig.update_layout(\n",
    "    title=\"Mean Color Distribution\",\n",
    "    xaxis_title=\"Color Value\",\n",
    "    yaxis_title=\"Number of Pixels\"\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90087109-bc45-4390-90c4-98d3e6dd7a8a",
   "metadata": {},
   "source": [
    "## Review some samples\n",
    "\n",
    "To get an idea of what a record looks like, but being mindful that we should only see minimal data to prevent add bias in later steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd46d27-a870-4381-bcb3-3e6f36634dc0",
   "metadata": {},
   "source": [
    "### Function to display images in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13815089-e6ed-4c55-99a4-99796a5daa2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert opencv BGR to RGB ordering\n",
    "def plt_imshow(title, image):\n",
    "\t# convert the image frame BGR to RGB color space and display it\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\tplt.imshow(image)\n",
    "\tplt.title(title)\n",
    "\tplt.grid(False)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c8dbab-dc7d-4906-939e-e82e68b8a9bd",
   "metadata": {},
   "source": [
    "### Display an sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8199199-87ea-4d67-b2fc-dc147572174b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(scratch_path + '/train/left/1__M_Left_index_finger_CR.png')\n",
    "\n",
    "(h, w, c) = image.shape[:3]\n",
    "\n",
    "# display the image dimensions\n",
    "print(\"width: {} pixels\".format(image.shape[1]))\n",
    "print(\"heigth: {} pixels\".format(image.shape[0]))\n",
    "print(\"channels: {}\".format(image.shape[2]))\n",
    "\n",
    "plt_imshow(\"Original\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35337ef-9d42-466b-a650-b9eab7ba5275",
   "metadata": {},
   "source": [
    "You will notice there is a border around the image that will definitely impact our models algorithm learning that all fingerprints will have this border. We should remove this because it not a marker that should be used for understanding fingerprints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d1de2-d5e0-4a34-9d1b-8f49d52724ed",
   "metadata": {},
   "source": [
    "### Crop the border\n",
    "\n",
    "Let's experiment with different values to crop the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f157ac7-6c11-4f90-8926-8a662b2c334d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cropping an image with OpenCV is accomplished via simple NumPy\n",
    "# array slices in startY:endY, startX:endX order\n",
    "# cropping the border from the image - expected optimal values [5:95, 5:90]\n",
    "\n",
    "CROP_TOP = 10\n",
    "CROP_BOT = 96-1\n",
    "CROP_L = 5\n",
    "CROP_R = 96-6\n",
    "\n",
    "no_border = image[CROP_TOP:CROP_BOT, CROP_L:CROP_R] # EXPERIMENT WITH CHANGES TO THESE VALUES AND DISPLAY THE OUTPUT\n",
    "\n",
    "(h, w, c) = no_border.shape[:3]\n",
    "\n",
    "# display the image dimensions\n",
    "print(\"width: {} pixels\".format(no_border.shape[1]))\n",
    "print(\"heigth: {} pixels\".format(no_border.shape[0]))\n",
    "print(\"channels: {}\".format(no_border.shape[2]))\n",
    "\n",
    "plt_imshow(\"Borderless\", no_border)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868dcd78-d149-4966-a800-6e73e314a730",
   "metadata": {},
   "source": [
    "# Overall\n",
    "\n",
    "We know we need to codify some changes:\n",
    "1. we need to rescale the images to be the same size\n",
    "1. then, we need to crop the border from around the image\n",
    "1. we need to create pipeline tasks that can be reused for data ingestion and against batch offline data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
